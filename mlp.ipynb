{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_EPOCH = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import preprossesing as pre\n",
    "import math\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(df):\n",
    "    \n",
    "    # df = pre.standardize(df)\n",
    "    df = pre.encoder(df)\n",
    "    df = df.drop(['id'], axis=1)\n",
    "\n",
    "    train, val = pre.test_validation_split(df)\n",
    "    \n",
    "    y_train = torch.tensor(train['price'].values, dtype=torch.float32)\n",
    "    X_train = train.drop(['price'], axis=1)\n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    \n",
    "    y_val = torch.tensor(val['price'].values, dtype=torch.float32)\n",
    "    X_val = val.drop(['price'], axis=1)\n",
    "    X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=175, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(175, 256),\n",
    "        nn.ReLU(), \n",
    "        \n",
    "        nn.Linear(256, 128),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        \n",
    "        nn.Linear(128, 1) \n",
    "        )\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.layers(x)\n",
    "\n",
    "model = mlp()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "X_train, y_train, X_val, y_val = prepare_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 19330.5390625 Validation loss: 19635.595703125 best Validation loss: 19635.595703125\n",
      "Epoch: 100 Loss: 13944.169921875 Validation loss: 14436.134765625 best Validation loss: 14436.134765625\n",
      "Epoch: 200 Loss: 8706.3544921875 Validation loss: 9001.63671875 best Validation loss: 9001.63671875\n",
      "Epoch: 300 Loss: 8101.75048828125 Validation loss: 8349.263671875 best Validation loss: 8349.263671875\n",
      "Epoch: 400 Loss: 8049.0576171875 Validation loss: 8276.2587890625 best Validation loss: 8276.2587890625\n",
      "Epoch: 500 Loss: 8023.96142578125 Validation loss: 8246.0380859375 best Validation loss: 8246.0380859375\n",
      "Epoch: 600 Loss: 8002.53369140625 Validation loss: 8221.62890625 best Validation loss: 8221.62890625\n",
      "Epoch: 700 Loss: 7983.03515625 Validation loss: 8200.2060546875 best Validation loss: 8200.2060546875\n",
      "Epoch: 800 Loss: 7964.0478515625 Validation loss: 8180.52294921875 best Validation loss: 8180.52294921875\n",
      "Epoch: 900 Loss: 7944.36279296875 Validation loss: 8160.95068359375 best Validation loss: 8160.95068359375\n",
      "Epoch: 1000 Loss: 7922.359375 Validation loss: 8139.3251953125 best Validation loss: 8139.3251953125\n",
      "Epoch: 1100 Loss: 7898.455078125 Validation loss: 8117.95068359375 best Validation loss: 8117.95068359375\n",
      "Epoch: 1200 Loss: 7873.38232421875 Validation loss: 8093.384765625 best Validation loss: 8093.384765625\n",
      "Epoch: 1300 Loss: 7846.1484375 Validation loss: 8066.01123046875 best Validation loss: 8066.01123046875\n",
      "Epoch: 1400 Loss: 7816.25732421875 Validation loss: 8035.00830078125 best Validation loss: 8035.00830078125\n",
      "Epoch: 1500 Loss: 7781.154296875 Validation loss: 8001.11962890625 best Validation loss: 8001.11962890625\n",
      "Epoch: 1600 Loss: 7741.7216796875 Validation loss: 7963.115234375 best Validation loss: 7962.42724609375\n",
      "Epoch: 1700 Loss: 7697.93798828125 Validation loss: 7918.5546875 best Validation loss: 7918.5546875\n",
      "Epoch: 1800 Loss: 7653.96826171875 Validation loss: 7883.00439453125 best Validation loss: 7867.60546875\n",
      "Epoch: 1900 Loss: 7598.189453125 Validation loss: 7817.89697265625 best Validation loss: 7817.55517578125\n",
      "Epoch: 2000 Loss: 7543.09130859375 Validation loss: 7760.8720703125 best Validation loss: 7760.8720703125\n",
      "Epoch: 2100 Loss: 7485.23486328125 Validation loss: 7701.4404296875 best Validation loss: 7701.4404296875\n",
      "Epoch: 2200 Loss: 7425.16455078125 Validation loss: 7638.21337890625 best Validation loss: 7638.21337890625\n",
      "Epoch: 2300 Loss: 7360.14453125 Validation loss: 7570.12451171875 best Validation loss: 7570.12451171875\n",
      "Epoch: 2400 Loss: 7294.13818359375 Validation loss: 7502.18408203125 best Validation loss: 7502.18408203125\n",
      "Epoch: 2500 Loss: 7230.77880859375 Validation loss: 7444.02783203125 best Validation loss: 7433.37109375\n",
      "Epoch: 2600 Loss: 7160.2119140625 Validation loss: 7368.21142578125 best Validation loss: 7361.97314453125\n",
      "Epoch: 2700 Loss: 7087.97607421875 Validation loss: 7293.10693359375 best Validation loss: 7285.73681640625\n",
      "Epoch: 2800 Loss: 7011.70068359375 Validation loss: 7212.86669921875 best Validation loss: 7209.916015625\n",
      "Epoch: 2900 Loss: 6933.34619140625 Validation loss: 7128.91259765625 best Validation loss: 7128.91259765625\n",
      "Epoch: 3000 Loss: 6849.3984375 Validation loss: 7048.29296875 best Validation loss: 7043.07275390625\n",
      "Epoch: 3100 Loss: 6758.7578125 Validation loss: 6958.3466796875 best Validation loss: 6953.26806640625\n",
      "Epoch: 3200 Loss: 6666.56005859375 Validation loss: 6860.662109375 best Validation loss: 6860.662109375\n",
      "Epoch: 3300 Loss: 6573.44580078125 Validation loss: 6765.486328125 best Validation loss: 6765.486328125\n",
      "Epoch: 3400 Loss: 6479.19287109375 Validation loss: 6687.58837890625 best Validation loss: 6667.76513671875\n",
      "Epoch: 3500 Loss: 6351.4296875 Validation loss: 6548.05908203125 best Validation loss: 6548.05908203125\n",
      "Epoch: 3600 Loss: 6236.15576171875 Validation loss: 6433.794921875 best Validation loss: 6430.82958984375\n",
      "Epoch: 3700 Loss: 6121.19384765625 Validation loss: 6312.47705078125 best Validation loss: 6312.47705078125\n",
      "Epoch: 3800 Loss: 6005.31005859375 Validation loss: 6193.2978515625 best Validation loss: 6193.2978515625\n",
      "Epoch: 3900 Loss: 5893.58984375 Validation loss: 6076.4755859375 best Validation loss: 6076.4755859375\n",
      "Epoch: 4000 Loss: 5779.568359375 Validation loss: 5968.85400390625 best Validation loss: 5959.35009765625\n",
      "Epoch: 4100 Loss: 5684.48486328125 Validation loss: 5894.0703125 best Validation loss: 5839.5224609375\n",
      "Epoch: 4200 Loss: 5547.1611328125 Validation loss: 5728.1513671875 best Validation loss: 5722.9912109375\n",
      "Epoch: 4300 Loss: 5438.810546875 Validation loss: 5615.85986328125 best Validation loss: 5611.2431640625\n",
      "Epoch: 4400 Loss: 5338.87646484375 Validation loss: 5513.3017578125 best Validation loss: 5506.4619140625\n",
      "Epoch: 4500 Loss: 5232.033203125 Validation loss: 5395.59912109375 best Validation loss: 5395.59912109375\n",
      "Epoch: 4600 Loss: 5143.09375 Validation loss: 5304.3828125 best Validation loss: 5301.71533203125\n",
      "Epoch: 4700 Loss: 5073.89697265625 Validation loss: 5219.5087890625 best Validation loss: 5207.35302734375\n",
      "Epoch: 4800 Loss: 4970.8427734375 Validation loss: 5133.5517578125 best Validation loss: 5112.33837890625\n",
      "Epoch: 4900 Loss: 4880.4697265625 Validation loss: 5018.5712890625 best Validation loss: 5018.5712890625\n",
      "Epoch: 5000 Loss: 4809.11962890625 Validation loss: 4949.17431640625 best Validation loss: 4944.4091796875\n",
      "Epoch: 5100 Loss: 4722.06494140625 Validation loss: 4859.8115234375 best Validation loss: 4859.8115234375\n",
      "Epoch: 5200 Loss: 4656.4287109375 Validation loss: 4788.78466796875 best Validation loss: 4788.78466796875\n",
      "Epoch: 5300 Loss: 4597.31103515625 Validation loss: 4723.181640625 best Validation loss: 4723.181640625\n",
      "Epoch: 5400 Loss: 4563.97802734375 Validation loss: 4678.388671875 best Validation loss: 4668.97998046875\n",
      "Epoch: 5500 Loss: 4489.89892578125 Validation loss: 4604.830078125 best Validation loss: 4604.830078125\n",
      "Epoch: 5600 Loss: 4440.921875 Validation loss: 4551.12158203125 best Validation loss: 4549.99462890625\n",
      "Epoch: 5700 Loss: 4396.3037109375 Validation loss: 4496.2666015625 best Validation loss: 4496.2666015625\n",
      "Epoch: 5800 Loss: 4357.10498046875 Validation loss: 4452.2841796875 best Validation loss: 4450.15869140625\n",
      "Epoch: 5900 Loss: 4318.83642578125 Validation loss: 4403.8408203125 best Validation loss: 4403.8408203125\n",
      "Epoch: 6000 Loss: 4272.54443359375 Validation loss: 4352.66796875 best Validation loss: 4352.66796875\n",
      "Epoch: 6100 Loss: 4257.90087890625 Validation loss: 4342.3876953125 best Validation loss: 4312.494140625\n",
      "Epoch: 6200 Loss: 4201.67529296875 Validation loss: 4267.62255859375 best Validation loss: 4267.62255859375\n",
      "Epoch: 6300 Loss: 4174.0849609375 Validation loss: 4233.10986328125 best Validation loss: 4231.326171875\n",
      "Epoch: 6400 Loss: 4149.2568359375 Validation loss: 4216.04931640625 best Validation loss: 4194.884765625\n",
      "Epoch: 6500 Loss: 4126.28125 Validation loss: 4183.27587890625 best Validation loss: 4162.69140625\n",
      "Epoch: 6600 Loss: 4090.420166015625 Validation loss: 4138.98095703125 best Validation loss: 4128.12890625\n",
      "Epoch: 6700 Loss: 4062.109130859375 Validation loss: 4103.177734375 best Validation loss: 4095.824462890625\n",
      "Epoch: 6800 Loss: 4033.7939453125 Validation loss: 4066.1728515625 best Validation loss: 4063.404052734375\n",
      "Epoch: 6900 Loss: 4011.873779296875 Validation loss: 4033.619384765625 best Validation loss: 4033.619384765625\n",
      "Epoch: 7000 Loss: 3987.893310546875 Validation loss: 4004.710693359375 best Validation loss: 4003.666748046875\n",
      "Epoch: 7100 Loss: 3962.705322265625 Validation loss: 3974.619384765625 best Validation loss: 3974.619384765625\n",
      "Epoch: 7200 Loss: 3937.25146484375 Validation loss: 3945.924072265625 best Validation loss: 3945.924072265625\n",
      "Epoch: 7300 Loss: 3915.33544921875 Validation loss: 3919.537109375 best Validation loss: 3919.34912109375\n",
      "Epoch: 7400 Loss: 3900.707763671875 Validation loss: 3902.8974609375 best Validation loss: 3896.051513671875\n",
      "Epoch: 7500 Loss: 3879.892333984375 Validation loss: 3880.3115234375 best Validation loss: 3868.6416015625\n",
      "Epoch: 7600 Loss: 3857.97119140625 Validation loss: 3843.50927734375 best Validation loss: 3842.82470703125\n",
      "Epoch: 7700 Loss: 3834.915283203125 Validation loss: 3819.8251953125 best Validation loss: 3818.76318359375\n",
      "Epoch: 7800 Loss: 3817.27685546875 Validation loss: 3798.97509765625 best Validation loss: 3795.156982421875\n",
      "Epoch: 7900 Loss: 3798.07958984375 Validation loss: 3771.954833984375 best Validation loss: 3771.954833984375\n",
      "Epoch: 8000 Loss: 3780.67041015625 Validation loss: 3751.555908203125 best Validation loss: 3749.2978515625\n",
      "Epoch: 8100 Loss: 3767.78173828125 Validation loss: 3735.16552734375 best Validation loss: 3728.81396484375\n",
      "Epoch: 8200 Loss: 3755.331298828125 Validation loss: 3721.511962890625 best Validation loss: 3710.118408203125\n",
      "Epoch: 8300 Loss: 3729.490966796875 Validation loss: 3684.49365234375 best Validation loss: 3684.49365234375\n",
      "Epoch: 8400 Loss: 3728.154541015625 Validation loss: 3668.1982421875 best Validation loss: 3664.660400390625\n",
      "Epoch: 8500 Loss: 3732.63818359375 Validation loss: 3693.651123046875 best Validation loss: 3640.85107421875\n",
      "Epoch: 8600 Loss: 3682.32958984375 Validation loss: 3626.037109375 best Validation loss: 3617.927978515625\n",
      "Epoch: 8700 Loss: 3669.530517578125 Validation loss: 3606.10986328125 best Validation loss: 3598.710205078125\n",
      "Epoch: 8800 Loss: 3653.099609375 Validation loss: 3592.48291015625 best Validation loss: 3577.781494140625\n",
      "Epoch: 8900 Loss: 3634.754150390625 Validation loss: 3559.431396484375 best Validation loss: 3556.8916015625\n",
      "Epoch: 9000 Loss: 3619.171630859375 Validation loss: 3536.9150390625 best Validation loss: 3536.9150390625\n",
      "Epoch: 9100 Loss: 3608.03466796875 Validation loss: 3518.86572265625 best Validation loss: 3518.390625\n",
      "Epoch: 9200 Loss: 3589.478515625 Validation loss: 3500.131103515625 best Validation loss: 3500.131103515625\n",
      "Epoch: 9300 Loss: 3584.146728515625 Validation loss: 3498.215576171875 best Validation loss: 3484.408935546875\n",
      "Epoch: 9400 Loss: 3561.29150390625 Validation loss: 3464.22216796875 best Validation loss: 3463.247802734375\n",
      "Epoch: 9500 Loss: 3558.892578125 Validation loss: 3451.78515625 best Validation loss: 3445.96044921875\n",
      "Epoch: 9600 Loss: 3535.54052734375 Validation loss: 3427.51171875 best Validation loss: 3427.51171875\n",
      "Epoch: 9700 Loss: 3530.627685546875 Validation loss: 3428.207275390625 best Validation loss: 3411.941650390625\n",
      "Epoch: 9800 Loss: 3534.2880859375 Validation loss: 3425.26806640625 best Validation loss: 3392.960693359375\n",
      "Epoch: 9900 Loss: 3505.651123046875 Validation loss: 3381.5732421875 best Validation loss: 3375.60400390625\n",
      "Epoch: 10000 Loss: 3481.65087890625 Validation loss: 3359.5595703125 best Validation loss: 3359.033447265625\n",
      "Epoch: 10100 Loss: 3479.930419921875 Validation loss: 3370.608642578125 best Validation loss: 3342.762451171875\n",
      "Epoch: 10200 Loss: 3460.4150390625 Validation loss: 3326.952880859375 best Validation loss: 3326.952880859375\n",
      "Epoch: 10300 Loss: 3452.58984375 Validation loss: 3312.386962890625 best Validation loss: 3312.386962890625\n",
      "Epoch: 10400 Loss: 3433.9580078125 Validation loss: 3296.209716796875 best Validation loss: 3296.209716796875\n",
      "Epoch: 10500 Loss: 3435.996337890625 Validation loss: 3305.835205078125 best Validation loss: 3283.826171875\n",
      "Epoch: 10600 Loss: 3411.337158203125 Validation loss: 3274.257080078125 best Validation loss: 3267.44873046875\n",
      "Epoch: 10700 Loss: 3401.56982421875 Validation loss: 3252.894775390625 best Validation loss: 3252.71484375\n",
      "Epoch: 10800 Loss: 3389.399658203125 Validation loss: 3245.398681640625 best Validation loss: 3239.2587890625\n",
      "Epoch: 10900 Loss: 3397.6630859375 Validation loss: 3237.381103515625 best Validation loss: 3226.310302734375\n",
      "Epoch: 11000 Loss: 3367.598876953125 Validation loss: 3213.557861328125 best Validation loss: 3211.905029296875\n",
      "Epoch: 11100 Loss: 3368.870849609375 Validation loss: 3224.916015625 best Validation loss: 3199.050537109375\n",
      "Epoch: 11200 Loss: 3357.0234375 Validation loss: 3201.69091796875 best Validation loss: 3186.665771484375\n",
      "Epoch: 11300 Loss: 3337.842529296875 Validation loss: 3172.4404296875 best Validation loss: 3172.4404296875\n",
      "Epoch: 11400 Loss: 3344.1064453125 Validation loss: 3189.94873046875 best Validation loss: 3160.92431640625\n",
      "Epoch: 11500 Loss: 3318.864501953125 Validation loss: 3149.551025390625 best Validation loss: 3147.23193359375\n",
      "Epoch: 11600 Loss: 3323.9833984375 Validation loss: 3165.991455078125 best Validation loss: 3137.054443359375\n",
      "Epoch: 11700 Loss: 3335.8984375 Validation loss: 3182.255126953125 best Validation loss: 3124.763671875\n",
      "Epoch: 11800 Loss: 3291.3779296875 Validation loss: 3114.410400390625 best Validation loss: 3113.013916015625\n",
      "Epoch: 11900 Loss: 3293.697509765625 Validation loss: 3130.578125 best Validation loss: 3102.5537109375\n",
      "Epoch: 12000 Loss: 3277.401123046875 Validation loss: 3089.839599609375 best Validation loss: 3089.839599609375\n",
      "Epoch: 12100 Loss: 3266.602783203125 Validation loss: 3086.24560546875 best Validation loss: 3079.541015625\n",
      "Epoch: 12200 Loss: 3270.40576171875 Validation loss: 3090.718017578125 best Validation loss: 3070.2919921875\n",
      "Epoch: 12300 Loss: 3250.072998046875 Validation loss: 3058.85498046875 best Validation loss: 3058.85498046875\n",
      "Epoch: 12400 Loss: 3246.28271484375 Validation loss: 3065.8037109375 best Validation loss: 3049.2978515625\n",
      "Epoch: 12500 Loss: 3235.47314453125 Validation loss: 3039.32080078125 best Validation loss: 3039.32080078125\n",
      "Epoch: 12600 Loss: 3235.96484375 Validation loss: 3034.095458984375 best Validation loss: 3030.40283203125\n",
      "Epoch: 12700 Loss: 3227.702392578125 Validation loss: 3021.828369140625 best Validation loss: 3021.828369140625\n",
      "Epoch: 12800 Loss: 3211.97412109375 Validation loss: 3013.205322265625 best Validation loss: 3012.156982421875\n",
      "Epoch: 12900 Loss: 3223.71923828125 Validation loss: 3040.52685546875 best Validation loss: 3003.39599609375\n",
      "Epoch: 13000 Loss: 3200.422607421875 Validation loss: 2993.890869140625 best Validation loss: 2993.890869140625\n",
      "Epoch: 13100 Loss: 3193.9453125 Validation loss: 2998.7705078125 best Validation loss: 2985.5087890625\n",
      "Epoch: 13200 Loss: 3206.735595703125 Validation loss: 3025.39208984375 best Validation loss: 2977.2353515625\n",
      "Epoch: 13300 Loss: 3178.77392578125 Validation loss: 2968.799560546875 best Validation loss: 2968.7607421875\n",
      "Epoch: 13400 Loss: 3191.281005859375 Validation loss: 2971.255615234375 best Validation loss: 2961.6015625\n",
      "Epoch: 13500 Loss: 3166.258544921875 Validation loss: 2958.092041015625 best Validation loss: 2953.9111328125\n",
      "Epoch: 13600 Loss: 3166.281005859375 Validation loss: 2968.74169921875 best Validation loss: 2946.01416015625\n",
      "Epoch: 13700 Loss: 3164.34033203125 Validation loss: 2958.713134765625 best Validation loss: 2939.49462890625\n",
      "Epoch: 13800 Loss: 3150.528564453125 Validation loss: 2935.813232421875 best Validation loss: 2930.31494140625\n",
      "Epoch: 13900 Loss: 3160.13623046875 Validation loss: 2961.55908203125 best Validation loss: 2924.466552734375\n",
      "Epoch: 14000 Loss: 3138.26708984375 Validation loss: 2925.3076171875 best Validation loss: 2916.40576171875\n",
      "Epoch: 14100 Loss: 3135.658447265625 Validation loss: 2911.5986328125 best Validation loss: 2910.32080078125\n",
      "Epoch: 14200 Loss: 3154.035888671875 Validation loss: 2925.377197265625 best Validation loss: 2903.587890625\n",
      "Epoch: 14300 Loss: 3119.257080078125 Validation loss: 2899.073486328125 best Validation loss: 2896.9130859375\n",
      "Epoch: 14400 Loss: 3113.995849609375 Validation loss: 2891.177978515625 best Validation loss: 2890.82421875\n",
      "Epoch: 14500 Loss: 3127.354248046875 Validation loss: 2916.861328125 best Validation loss: 2885.07763671875\n",
      "Epoch: 14600 Loss: 3103.6865234375 Validation loss: 2878.215576171875 best Validation loss: 2878.215576171875\n",
      "Epoch: 14700 Loss: 3114.287353515625 Validation loss: 2882.4287109375 best Validation loss: 2872.032470703125\n",
      "Epoch: 14800 Loss: 3100.35986328125 Validation loss: 2869.3583984375 best Validation loss: 2866.29833984375\n",
      "Epoch: 14900 Loss: 3118.513427734375 Validation loss: 2880.010986328125 best Validation loss: 2860.4794921875\n",
      "Epoch: 15000 Loss: 3101.013671875 Validation loss: 2881.243896484375 best Validation loss: 2854.67333984375\n",
      "Epoch: 15100 Loss: 3079.4853515625 Validation loss: 2850.823974609375 best Validation loss: 2848.013671875\n",
      "Epoch: 15200 Loss: 3075.6572265625 Validation loss: 2842.3515625 best Validation loss: 2842.3515625\n",
      "Epoch: 15300 Loss: 3104.512939453125 Validation loss: 2860.215087890625 best Validation loss: 2837.80224609375\n",
      "Epoch: 15400 Loss: 3066.200927734375 Validation loss: 2838.39599609375 best Validation loss: 2832.144775390625\n",
      "Epoch: 15500 Loss: 3077.0517578125 Validation loss: 2831.188232421875 best Validation loss: 2826.989013671875\n",
      "Epoch: 15600 Loss: 3057.86962890625 Validation loss: 2832.153076171875 best Validation loss: 2821.21337890625\n",
      "Epoch: 15700 Loss: 3072.339111328125 Validation loss: 2825.55419921875 best Validation loss: 2816.581298828125\n",
      "Epoch: 15800 Loss: 3049.31494140625 Validation loss: 2811.273193359375 best Validation loss: 2810.76171875\n",
      "Epoch: 15900 Loss: 3053.932861328125 Validation loss: 2811.5546875 best Validation loss: 2806.228759765625\n",
      "Epoch: 16000 Loss: 3040.165771484375 Validation loss: 2806.026123046875 best Validation loss: 2801.5205078125\n",
      "Epoch: 16100 Loss: 3047.078125 Validation loss: 2815.9814453125 best Validation loss: 2797.274658203125\n",
      "Epoch: 16200 Loss: 3033.291015625 Validation loss: 2801.306884765625 best Validation loss: 2791.70703125\n",
      "Epoch: 16300 Loss: 3050.796630859375 Validation loss: 2828.77978515625 best Validation loss: 2787.2666015625\n",
      "Epoch: 16400 Loss: 3025.10693359375 Validation loss: 2782.642822265625 best Validation loss: 2782.478759765625\n",
      "Epoch: 16500 Loss: 3020.3662109375 Validation loss: 2782.965087890625 best Validation loss: 2777.80224609375\n",
      "Epoch: 16600 Loss: 3018.555419921875 Validation loss: 2780.6787109375 best Validation loss: 2773.775146484375\n",
      "Epoch: 16700 Loss: 3016.47412109375 Validation loss: 2770.801513671875 best Validation loss: 2769.315673828125\n",
      "Epoch: 16800 Loss: 3014.999267578125 Validation loss: 2765.0439453125 best Validation loss: 2765.0439453125\n",
      "Epoch: 16900 Loss: 3006.0322265625 Validation loss: 2768.166015625 best Validation loss: 2760.701171875\n",
      "Epoch: 17000 Loss: 3002.707275390625 Validation loss: 2756.35107421875 best Validation loss: 2756.35107421875\n",
      "Epoch: 17100 Loss: 3000.844482421875 Validation loss: 2752.06591796875 best Validation loss: 2752.06591796875\n",
      "Epoch: 17200 Loss: 3004.08251953125 Validation loss: 2754.444580078125 best Validation loss: 2748.36279296875\n",
      "Epoch: 17300 Loss: 2992.801025390625 Validation loss: 2749.7998046875 best Validation loss: 2744.122802734375\n",
      "Epoch: 17400 Loss: 2997.281982421875 Validation loss: 2766.3505859375 best Validation loss: 2740.57275390625\n",
      "Epoch: 17500 Loss: 2986.635009765625 Validation loss: 2743.153076171875 best Validation loss: 2736.614990234375\n",
      "Epoch: 17600 Loss: 2981.029296875 Validation loss: 2737.84619140625 best Validation loss: 2732.737548828125\n",
      "Epoch: 17700 Loss: 3008.076416015625 Validation loss: 2774.89599609375 best Validation loss: 2729.5029296875\n",
      "Epoch: 17800 Loss: 2973.909423828125 Validation loss: 2727.8671875 best Validation loss: 2725.836181640625\n",
      "Epoch: 17900 Loss: 3000.661865234375 Validation loss: 2741.1416015625 best Validation loss: 2722.594482421875\n",
      "Epoch: 18000 Loss: 2968.086181640625 Validation loss: 2721.521728515625 best Validation loss: 2718.5888671875\n",
      "Epoch: 18100 Loss: 2973.238525390625 Validation loss: 2740.84033203125 best Validation loss: 2715.0\n",
      "Epoch: 18200 Loss: 2989.08251953125 Validation loss: 2749.10400390625 best Validation loss: 2712.107666015625\n",
      "Epoch: 18300 Loss: 2960.46875 Validation loss: 2708.755126953125 best Validation loss: 2708.093505859375\n",
      "Epoch: 18400 Loss: 2959.8837890625 Validation loss: 2706.581298828125 best Validation loss: 2703.668212890625\n",
      "Epoch: 18500 Loss: 2968.55419921875 Validation loss: 2706.7939453125 best Validation loss: 2700.828857421875\n",
      "Epoch: 18600 Loss: 2948.3759765625 Validation loss: 2697.343017578125 best Validation loss: 2697.343017578125\n",
      "Epoch: 18700 Loss: 2967.7265625 Validation loss: 2725.1103515625 best Validation loss: 2694.50146484375\n",
      "Epoch: 18800 Loss: 2943.707275390625 Validation loss: 2697.654296875 best Validation loss: 2690.60693359375\n",
      "Epoch: 18900 Loss: 2940.7841796875 Validation loss: 2687.54248046875 best Validation loss: 2687.54248046875\n",
      "Epoch: 19000 Loss: 2962.218994140625 Validation loss: 2700.644287109375 best Validation loss: 2684.088623046875\n",
      "Epoch: 19100 Loss: 2954.102294921875 Validation loss: 2704.58642578125 best Validation loss: 2680.544921875\n",
      "Epoch: 19200 Loss: 2951.97900390625 Validation loss: 2693.92919921875 best Validation loss: 2676.4599609375\n",
      "Epoch: 19300 Loss: 2930.263671875 Validation loss: 2673.962158203125 best Validation loss: 2673.068359375\n",
      "Epoch: 19400 Loss: 2925.6533203125 Validation loss: 2669.7880859375 best Validation loss: 2669.7880859375\n",
      "Epoch: 19500 Loss: 2930.531982421875 Validation loss: 2691.103759765625 best Validation loss: 2666.994384765625\n",
      "Epoch: 19600 Loss: 2919.07421875 Validation loss: 2666.005859375 best Validation loss: 2663.894775390625\n",
      "Epoch: 19700 Loss: 2948.400146484375 Validation loss: 2682.391357421875 best Validation loss: 2660.991455078125\n",
      "Epoch: 19800 Loss: 2925.150146484375 Validation loss: 2677.59716796875 best Validation loss: 2658.71044921875\n",
      "Epoch: 19900 Loss: 2917.281494140625 Validation loss: 2672.571533203125 best Validation loss: 2655.809814453125\n",
      "Epoch: 20000 Loss: 2921.361083984375 Validation loss: 2656.1025390625 best Validation loss: 2653.215576171875\n",
      "Epoch: 20100 Loss: 2930.046630859375 Validation loss: 2667.6015625 best Validation loss: 2650.37939453125\n",
      "Epoch: 20200 Loss: 2903.20947265625 Validation loss: 2647.061279296875 best Validation loss: 2647.061279296875\n",
      "Epoch: 20300 Loss: 2927.546875 Validation loss: 2685.02587890625 best Validation loss: 2645.420166015625\n",
      "Epoch: 20400 Loss: 2897.887939453125 Validation loss: 2643.27294921875 best Validation loss: 2642.20654296875\n",
      "Epoch: 20500 Loss: 2916.53173828125 Validation loss: 2670.098388671875 best Validation loss: 2639.7734375\n",
      "Epoch: 20600 Loss: 2895.55908203125 Validation loss: 2638.43701171875 best Validation loss: 2636.818359375\n",
      "Epoch: 20700 Loss: 2894.19189453125 Validation loss: 2634.81005859375 best Validation loss: 2634.81005859375\n",
      "Epoch: 20800 Loss: 2911.477294921875 Validation loss: 2682.81103515625 best Validation loss: 2632.572509765625\n",
      "Epoch: 20900 Loss: 2885.3046875 Validation loss: 2632.9296875 best Validation loss: 2630.23095703125\n",
      "Epoch: 21000 Loss: 2887.99609375 Validation loss: 2627.942626953125 best Validation loss: 2627.861328125\n",
      "Epoch: 21100 Loss: 2909.415283203125 Validation loss: 2643.56103515625 best Validation loss: 2625.62109375\n",
      "Epoch: 21200 Loss: 2878.1240234375 Validation loss: 2622.880615234375 best Validation loss: 2622.880615234375\n",
      "Epoch: 21300 Loss: 2877.0810546875 Validation loss: 2620.706298828125 best Validation loss: 2620.14990234375\n",
      "Epoch: 21400 Loss: 2899.425537109375 Validation loss: 2641.548828125 best Validation loss: 2618.73583984375\n",
      "Epoch: 21500 Loss: 2870.850830078125 Validation loss: 2617.906494140625 best Validation loss: 2616.77197265625\n",
      "Epoch: 21600 Loss: 2868.6396484375 Validation loss: 2615.764892578125 best Validation loss: 2614.2705078125\n",
      "Epoch: 21700 Loss: 2875.357666015625 Validation loss: 2624.673583984375 best Validation loss: 2612.674560546875\n",
      "Epoch: 21800 Loss: 2894.1953125 Validation loss: 2628.770751953125 best Validation loss: 2610.703125\n",
      "Epoch: 21900 Loss: 2879.463623046875 Validation loss: 2643.7900390625 best Validation loss: 2608.287353515625\n",
      "Epoch: 22000 Loss: 2864.492919921875 Validation loss: 2625.143310546875 best Validation loss: 2606.33447265625\n",
      "Epoch: 22100 Loss: 2857.234130859375 Validation loss: 2604.035400390625 best Validation loss: 2603.91455078125\n",
      "Epoch: 22200 Loss: 2858.927734375 Validation loss: 2609.4873046875 best Validation loss: 2602.43212890625\n",
      "Epoch: 22300 Loss: 2856.431884765625 Validation loss: 2602.982666015625 best Validation loss: 2600.098388671875\n",
      "Epoch: 22400 Loss: 2850.277587890625 Validation loss: 2603.0537109375 best Validation loss: 2597.92724609375\n",
      "Epoch: 22500 Loss: 2847.26953125 Validation loss: 2596.460693359375 best Validation loss: 2596.460693359375\n",
      "Epoch: 22600 Loss: 2849.29541015625 Validation loss: 2594.0458984375 best Validation loss: 2594.0458984375\n",
      "Epoch: 22700 Loss: 2847.7158203125 Validation loss: 2596.8935546875 best Validation loss: 2592.812744140625\n",
      "Epoch: 22800 Loss: 2853.617431640625 Validation loss: 2596.550048828125 best Validation loss: 2591.14794921875\n",
      "Epoch: 22900 Loss: 2844.398193359375 Validation loss: 2593.214111328125 best Validation loss: 2588.916015625\n",
      "Epoch: 23000 Loss: 2835.67919921875 Validation loss: 2589.383544921875 best Validation loss: 2586.9365234375\n",
      "Epoch: 23100 Loss: 2837.04443359375 Validation loss: 2585.495361328125 best Validation loss: 2585.253173828125\n",
      "Epoch: 23200 Loss: 2840.46044921875 Validation loss: 2585.303955078125 best Validation loss: 2583.685791015625\n",
      "Epoch: 23300 Loss: 2863.03076171875 Validation loss: 2601.8134765625 best Validation loss: 2581.835205078125\n",
      "Epoch: 23400 Loss: 2837.70947265625 Validation loss: 2597.378173828125 best Validation loss: 2580.427978515625\n",
      "Epoch: 23500 Loss: 2834.071533203125 Validation loss: 2586.513427734375 best Validation loss: 2577.932373046875\n",
      "Epoch: 23600 Loss: 2838.356201171875 Validation loss: 2583.603759765625 best Validation loss: 2576.86376953125\n",
      "Epoch: 23700 Loss: 2857.871337890625 Validation loss: 2600.98095703125 best Validation loss: 2575.442626953125\n",
      "Epoch: 23800 Loss: 2832.212890625 Validation loss: 2594.450927734375 best Validation loss: 2573.631103515625\n",
      "Epoch: 23900 Loss: 2839.697021484375 Validation loss: 2620.680908203125 best Validation loss: 2571.824462890625\n",
      "Epoch: 24000 Loss: 2837.257080078125 Validation loss: 2602.410400390625 best Validation loss: 2571.04052734375\n",
      "Epoch: 24100 Loss: 2819.143798828125 Validation loss: 2591.37060546875 best Validation loss: 2569.13916015625\n",
      "Epoch: 24200 Loss: 2838.403076171875 Validation loss: 2593.35498046875 best Validation loss: 2567.842041015625\n",
      "Epoch: 24300 Loss: 2813.743408203125 Validation loss: 2584.9677734375 best Validation loss: 2565.6875\n",
      "Epoch: 24400 Loss: 2830.790283203125 Validation loss: 2604.68994140625 best Validation loss: 2564.83837890625\n",
      "Epoch: 24500 Loss: 2821.977294921875 Validation loss: 2590.34130859375 best Validation loss: 2563.410888671875\n",
      "Epoch: 24600 Loss: 2825.030029296875 Validation loss: 2609.410400390625 best Validation loss: 2561.804443359375\n",
      "Epoch: 24700 Loss: 2804.33056640625 Validation loss: 2577.064208984375 best Validation loss: 2560.206298828125\n",
      "Epoch: 24800 Loss: 2800.0 Validation loss: 2560.149658203125 best Validation loss: 2558.8974609375\n",
      "Epoch: 24900 Loss: 2798.628173828125 Validation loss: 2569.8935546875 best Validation loss: 2557.18408203125\n",
      "Epoch: 25000 Loss: 2795.244384765625 Validation loss: 2564.9208984375 best Validation loss: 2555.764892578125\n",
      "Epoch: 25100 Loss: 2792.236328125 Validation loss: 2561.095703125 best Validation loss: 2554.189697265625\n",
      "Epoch: 25200 Loss: 2794.35498046875 Validation loss: 2568.48779296875 best Validation loss: 2552.72900390625\n",
      "Epoch: 25300 Loss: 2807.069580078125 Validation loss: 2565.990966796875 best Validation loss: 2551.60791015625\n",
      "Epoch: 25400 Loss: 2813.64306640625 Validation loss: 2569.890869140625 best Validation loss: 2550.58935546875\n",
      "Epoch: 25500 Loss: 2804.46337890625 Validation loss: 2566.9814453125 best Validation loss: 2549.177978515625\n",
      "Epoch: 25600 Loss: 2798.609375 Validation loss: 2564.48828125 best Validation loss: 2547.509765625\n",
      "Epoch: 25700 Loss: 2805.888916015625 Validation loss: 2596.2666015625 best Validation loss: 2546.14404296875\n",
      "Epoch: 25800 Loss: 2807.815673828125 Validation loss: 2598.545166015625 best Validation loss: 2544.896728515625\n",
      "Epoch: 25900 Loss: 2806.66357421875 Validation loss: 2577.68798828125 best Validation loss: 2543.618896484375\n",
      "Epoch: 26000 Loss: 2775.273681640625 Validation loss: 2542.699951171875 best Validation loss: 2542.257568359375\n",
      "Epoch: 26100 Loss: 2771.212158203125 Validation loss: 2544.07958984375 best Validation loss: 2540.73828125\n",
      "Epoch: 26200 Loss: 2775.126708984375 Validation loss: 2539.813720703125 best Validation loss: 2539.5869140625\n",
      "Epoch: 26300 Loss: 2788.305419921875 Validation loss: 2546.7509765625 best Validation loss: 2538.38525390625\n",
      "Epoch: 26400 Loss: 2767.155517578125 Validation loss: 2541.344482421875 best Validation loss: 2536.991943359375\n",
      "Epoch: 26500 Loss: 2767.56689453125 Validation loss: 2544.888427734375 best Validation loss: 2536.135009765625\n",
      "Epoch: 26600 Loss: 2766.929443359375 Validation loss: 2541.37890625 best Validation loss: 2534.838623046875\n",
      "Epoch: 26700 Loss: 2764.452392578125 Validation loss: 2540.67138671875 best Validation loss: 2533.19580078125\n",
      "Epoch: 26800 Loss: 2764.407470703125 Validation loss: 2543.20654296875 best Validation loss: 2532.247314453125\n",
      "Epoch: 26900 Loss: 2759.49658203125 Validation loss: 2538.3017578125 best Validation loss: 2530.74267578125\n",
      "Epoch: 27000 Loss: 2757.694091796875 Validation loss: 2537.197509765625 best Validation loss: 2529.238037109375\n",
      "Epoch: 27100 Loss: 2781.061767578125 Validation loss: 2549.909423828125 best Validation loss: 2524.60400390625\n",
      "Epoch: 27200 Loss: 2789.655029296875 Validation loss: 2575.36328125 best Validation loss: 2522.9658203125\n",
      "Epoch: 27300 Loss: 2760.16796875 Validation loss: 2527.02978515625 best Validation loss: 2521.919189453125\n",
      "Epoch: 27400 Loss: 2771.535888671875 Validation loss: 2534.04638671875 best Validation loss: 2520.698486328125\n",
      "Epoch: 27500 Loss: 2779.413330078125 Validation loss: 2545.22265625 best Validation loss: 2519.089599609375\n",
      "Epoch: 27600 Loss: 2758.052001953125 Validation loss: 2554.254150390625 best Validation loss: 2518.193359375\n",
      "Epoch: 27700 Loss: 2746.889404296875 Validation loss: 2535.77294921875 best Validation loss: 2517.35400390625\n",
      "Epoch: 27800 Loss: 2744.576416015625 Validation loss: 2521.1572265625 best Validation loss: 2516.208251953125\n",
      "Epoch: 27900 Loss: 2751.893310546875 Validation loss: 2530.030517578125 best Validation loss: 2515.021728515625\n",
      "Epoch: 28000 Loss: 2749.697509765625 Validation loss: 2520.54052734375 best Validation loss: 2514.260986328125\n",
      "Epoch: 28100 Loss: 2771.04736328125 Validation loss: 2544.0498046875 best Validation loss: 2512.932373046875\n",
      "Epoch: 28200 Loss: 2742.789794921875 Validation loss: 2540.0322265625 best Validation loss: 2511.58544921875\n",
      "Epoch: 28300 Loss: 2762.875 Validation loss: 2568.412353515625 best Validation loss: 2510.82177734375\n",
      "Epoch: 28400 Loss: 2766.86376953125 Validation loss: 2562.775390625 best Validation loss: 2509.419189453125\n",
      "Epoch: 28500 Loss: 2765.7451171875 Validation loss: 2566.799560546875 best Validation loss: 2508.53515625\n",
      "Epoch: 28600 Loss: 2759.339111328125 Validation loss: 2562.7890625 best Validation loss: 2506.688232421875\n",
      "Epoch: 28700 Loss: 2739.268798828125 Validation loss: 2542.33154296875 best Validation loss: 2505.69482421875\n",
      "Epoch: 28800 Loss: 2736.912109375 Validation loss: 2541.265625 best Validation loss: 2504.14404296875\n",
      "Epoch: 28900 Loss: 2747.819580078125 Validation loss: 2544.15380859375 best Validation loss: 2503.5234375\n",
      "Epoch: 29000 Loss: 2720.946044921875 Validation loss: 2514.83740234375 best Validation loss: 2502.593994140625\n",
      "Epoch: 29100 Loss: 2745.158935546875 Validation loss: 2526.68408203125 best Validation loss: 2501.59814453125\n",
      "Epoch: 29200 Loss: 2731.330078125 Validation loss: 2537.830810546875 best Validation loss: 2500.605712890625\n",
      "Epoch: 29300 Loss: 2733.609375 Validation loss: 2524.55517578125 best Validation loss: 2499.35107421875\n",
      "Epoch: 29400 Loss: 2746.172607421875 Validation loss: 2540.249755859375 best Validation loss: 2499.04833984375\n",
      "Epoch: 29500 Loss: 2750.333251953125 Validation loss: 2525.7822265625 best Validation loss: 2498.207275390625\n",
      "Epoch: 29600 Loss: 2709.18017578125 Validation loss: 2498.2099609375 best Validation loss: 2497.181884765625\n",
      "Epoch: 29700 Loss: 2731.756103515625 Validation loss: 2508.470458984375 best Validation loss: 2496.2109375\n",
      "Epoch: 29800 Loss: 2714.52099609375 Validation loss: 2498.080078125 best Validation loss: 2495.495361328125\n",
      "Epoch: 29900 Loss: 2702.943603515625 Validation loss: 2494.9833984375 best Validation loss: 2494.9833984375\n",
      "Epoch: 30000 Loss: 2705.432373046875 Validation loss: 2495.00341796875 best Validation loss: 2493.882568359375\n",
      "Epoch: 30100 Loss: 2702.1953125 Validation loss: 2498.447509765625 best Validation loss: 2493.37353515625\n",
      "Epoch: 30200 Loss: 2727.356201171875 Validation loss: 2506.262451171875 best Validation loss: 2492.42333984375\n",
      "Epoch: 30300 Loss: 2696.35791015625 Validation loss: 2494.135498046875 best Validation loss: 2491.450439453125\n",
      "Epoch: 30400 Loss: 2695.7587890625 Validation loss: 2491.3349609375 best Validation loss: 2490.615966796875\n",
      "Epoch: 30500 Loss: 2693.370361328125 Validation loss: 2489.89306640625 best Validation loss: 2489.89306640625\n",
      "Epoch: 30600 Loss: 2710.5302734375 Validation loss: 2506.009521484375 best Validation loss: 2489.236083984375\n",
      "Epoch: 30700 Loss: 2713.3779296875 Validation loss: 2532.09765625 best Validation loss: 2488.468505859375\n",
      "Epoch: 30800 Loss: 2701.86474609375 Validation loss: 2516.873046875 best Validation loss: 2487.745361328125\n",
      "Epoch: 30900 Loss: 2687.1728515625 Validation loss: 2487.8984375 best Validation loss: 2487.00830078125\n",
      "Epoch: 31000 Loss: 2714.145751953125 Validation loss: 2535.1162109375 best Validation loss: 2485.962158203125\n",
      "Epoch: 31100 Loss: 2708.10498046875 Validation loss: 2531.12744140625 best Validation loss: 2485.320068359375\n",
      "Epoch: 31200 Loss: 2717.183349609375 Validation loss: 2532.39599609375 best Validation loss: 2484.385986328125\n",
      "Epoch: 31300 Loss: 2706.6923828125 Validation loss: 2531.27001953125 best Validation loss: 2483.822998046875\n",
      "Epoch: 31400 Loss: 2714.568359375 Validation loss: 2535.0810546875 best Validation loss: 2483.045166015625\n",
      "Epoch: 31500 Loss: 2709.611083984375 Validation loss: 2535.6845703125 best Validation loss: 2482.256591796875\n",
      "Epoch: 31600 Loss: 2711.49365234375 Validation loss: 2534.462646484375 best Validation loss: 2481.5703125\n",
      "Epoch: 31700 Loss: 2702.828369140625 Validation loss: 2530.13232421875 best Validation loss: 2481.02197265625\n",
      "Epoch: 31800 Loss: 2679.027587890625 Validation loss: 2494.8408203125 best Validation loss: 2479.900146484375\n",
      "Epoch: 31900 Loss: 2673.851318359375 Validation loss: 2485.66064453125 best Validation loss: 2479.431396484375\n",
      "Epoch: 32000 Loss: 2670.95068359375 Validation loss: 2479.472900390625 best Validation loss: 2478.872802734375\n",
      "Epoch: 32100 Loss: 2671.193603515625 Validation loss: 2483.835693359375 best Validation loss: 2478.205078125\n",
      "Epoch: 32200 Loss: 2669.48193359375 Validation loss: 2479.833984375 best Validation loss: 2477.538330078125\n",
      "Epoch: 32300 Loss: 2667.951904296875 Validation loss: 2479.468994140625 best Validation loss: 2477.16455078125\n",
      "Epoch: 32400 Loss: 2703.886474609375 Validation loss: 2508.379638671875 best Validation loss: 2475.685791015625\n",
      "Epoch: 32500 Loss: 2668.849853515625 Validation loss: 2490.6953125 best Validation loss: 2474.850341796875\n",
      "Epoch: 32600 Loss: 2662.717529296875 Validation loss: 2478.2607421875 best Validation loss: 2474.466552734375\n",
      "Epoch: 32700 Loss: 2663.97900390625 Validation loss: 2475.17724609375 best Validation loss: 2474.15478515625\n",
      "Epoch: 32800 Loss: 2659.636474609375 Validation loss: 2474.18896484375 best Validation loss: 2473.43603515625\n",
      "Epoch: 32900 Loss: 2675.58984375 Validation loss: 2479.298095703125 best Validation loss: 2472.688232421875\n",
      "Epoch: 33000 Loss: 2691.04931640625 Validation loss: 2515.834228515625 best Validation loss: 2471.96484375\n",
      "Epoch: 33100 Loss: 2675.4248046875 Validation loss: 2511.615478515625 best Validation loss: 2471.1767578125\n",
      "Epoch: 33200 Loss: 2654.2080078125 Validation loss: 2471.0703125 best Validation loss: 2470.603759765625\n",
      "Epoch: 33300 Loss: 2653.193359375 Validation loss: 2470.371337890625 best Validation loss: 2469.888916015625\n",
      "Epoch: 33400 Loss: 2651.536865234375 Validation loss: 2472.54833984375 best Validation loss: 2469.606201171875\n",
      "Epoch: 33500 Loss: 2650.178955078125 Validation loss: 2469.29638671875 best Validation loss: 2469.046630859375\n",
      "Epoch: 33600 Loss: 2650.16943359375 Validation loss: 2470.428466796875 best Validation loss: 2467.703857421875\n",
      "Epoch: 33700 Loss: 2694.36328125 Validation loss: 2495.5947265625 best Validation loss: 2467.693359375\n",
      "Epoch: 33800 Loss: 2685.677490234375 Validation loss: 2488.55517578125 best Validation loss: 2467.228515625\n",
      "Epoch: 33900 Loss: 2691.31787109375 Validation loss: 2497.64306640625 best Validation loss: 2466.087646484375\n",
      "Epoch: 34000 Loss: 2655.67333984375 Validation loss: 2470.561279296875 best Validation loss: 2465.9658203125\n",
      "Epoch: 34100 Loss: 2646.015869140625 Validation loss: 2465.85302734375 best Validation loss: 2465.4169921875\n",
      "Epoch: 34200 Loss: 2647.376220703125 Validation loss: 2473.77099609375 best Validation loss: 2464.603271484375\n",
      "Epoch: 34300 Loss: 2659.19970703125 Validation loss: 2485.195556640625 best Validation loss: 2464.302734375\n",
      "Epoch: 34400 Loss: 2638.849853515625 Validation loss: 2467.0107421875 best Validation loss: 2463.52294921875\n",
      "Epoch: 34500 Loss: 2638.675537109375 Validation loss: 2469.854736328125 best Validation loss: 2463.036376953125\n",
      "Epoch: 34600 Loss: 2655.865478515625 Validation loss: 2481.72607421875 best Validation loss: 2462.860595703125\n",
      "Epoch: 34700 Loss: 2671.1376953125 Validation loss: 2519.9501953125 best Validation loss: 2462.07177734375\n",
      "Epoch: 34800 Loss: 2648.385009765625 Validation loss: 2477.471435546875 best Validation loss: 2461.677978515625\n",
      "Epoch: 34900 Loss: 2673.622802734375 Validation loss: 2495.367431640625 best Validation loss: 2461.316650390625\n",
      "Epoch: 35000 Loss: 2672.802001953125 Validation loss: 2511.035888671875 best Validation loss: 2460.47314453125\n",
      "Epoch: 35100 Loss: 2633.05517578125 Validation loss: 2466.360595703125 best Validation loss: 2460.345458984375\n",
      "Epoch: 35200 Loss: 2656.195556640625 Validation loss: 2489.55078125 best Validation loss: 2459.8388671875\n",
      "Epoch: 35300 Loss: 2649.31884765625 Validation loss: 2483.411865234375 best Validation loss: 2459.24755859375\n",
      "Epoch: 35400 Loss: 2629.93701171875 Validation loss: 2460.458984375 best Validation loss: 2458.19287109375\n",
      "Epoch: 35500 Loss: 2626.693359375 Validation loss: 2463.34814453125 best Validation loss: 2458.01123046875\n",
      "Epoch: 35600 Loss: 2643.843994140625 Validation loss: 2478.011474609375 best Validation loss: 2457.715087890625\n",
      "Epoch: 35700 Loss: 2627.96630859375 Validation loss: 2472.2861328125 best Validation loss: 2457.280517578125\n",
      "Epoch: 35800 Loss: 2639.716064453125 Validation loss: 2481.8935546875 best Validation loss: 2457.280517578125\n",
      "Epoch: 35900 Loss: 2625.61474609375 Validation loss: 2468.74267578125 best Validation loss: 2457.280517578125\n",
      "Epoch: 36000 Loss: 2630.713134765625 Validation loss: 2480.711181640625 best Validation loss: 2457.280517578125\n",
      "Epoch: 36100 Loss: 2645.856689453125 Validation loss: 2498.650146484375 best Validation loss: 2454.368408203125\n",
      "Epoch: 36200 Loss: 2652.467529296875 Validation loss: 2501.75 best Validation loss: 2452.003662109375\n",
      "Epoch: 36300 Loss: 2619.29248046875 Validation loss: 2469.8720703125 best Validation loss: 2450.680908203125\n",
      "Epoch: 36400 Loss: 2626.301513671875 Validation loss: 2483.7236328125 best Validation loss: 2449.78125\n",
      "Epoch: 36500 Loss: 2609.896240234375 Validation loss: 2450.240234375 best Validation loss: 2449.729736328125\n",
      "Epoch: 36600 Loss: 2609.1298828125 Validation loss: 2449.384033203125 best Validation loss: 2449.155029296875\n",
      "Epoch: 36700 Loss: 2623.587646484375 Validation loss: 2481.672607421875 best Validation loss: 2448.489013671875\n",
      "Epoch: 36800 Loss: 2618.896484375 Validation loss: 2478.01220703125 best Validation loss: 2447.763671875\n",
      "Epoch: 36900 Loss: 2641.684814453125 Validation loss: 2507.325439453125 best Validation loss: 2447.365966796875\n",
      "Epoch: 37000 Loss: 2618.51318359375 Validation loss: 2462.75439453125 best Validation loss: 2446.427978515625\n",
      "Epoch: 37100 Loss: 2608.25390625 Validation loss: 2452.070068359375 best Validation loss: 2446.203369140625\n",
      "Epoch: 37200 Loss: 2644.11767578125 Validation loss: 2475.368408203125 best Validation loss: 2445.469970703125\n",
      "Epoch: 37300 Loss: 2634.3046875 Validation loss: 2462.572509765625 best Validation loss: 2444.802001953125\n",
      "Epoch: 37400 Loss: 2607.6708984375 Validation loss: 2463.967041015625 best Validation loss: 2444.13330078125\n",
      "Epoch: 37500 Loss: 2616.7958984375 Validation loss: 2478.67822265625 best Validation loss: 2444.13330078125\n",
      "Epoch: 37600 Loss: 2622.701171875 Validation loss: 2478.75927734375 best Validation loss: 2444.13330078125\n",
      "Epoch: 37700 Loss: 2608.008544921875 Validation loss: 2460.3095703125 best Validation loss: 2443.91162109375\n",
      "Epoch: 37800 Loss: 2600.302734375 Validation loss: 2452.077392578125 best Validation loss: 2442.844970703125\n",
      "Epoch: 37900 Loss: 2597.666748046875 Validation loss: 2447.619384765625 best Validation loss: 2441.2099609375\n",
      "Epoch: 38000 Loss: 2603.4931640625 Validation loss: 2445.30859375 best Validation loss: 2440.726318359375\n",
      "Epoch: 38100 Loss: 2590.86376953125 Validation loss: 2441.0595703125 best Validation loss: 2440.0703125\n",
      "Epoch: 38200 Loss: 2609.293212890625 Validation loss: 2458.968017578125 best Validation loss: 2439.879150390625\n",
      "Epoch: 38300 Loss: 2594.436279296875 Validation loss: 2442.355224609375 best Validation loss: 2439.879150390625\n",
      "Epoch: 38400 Loss: 2605.46240234375 Validation loss: 2455.3173828125 best Validation loss: 2439.879150390625\n",
      "Epoch: 38500 Loss: 2590.8369140625 Validation loss: 2442.2236328125 best Validation loss: 2439.879150390625\n",
      "Epoch: 38600 Loss: 2607.724365234375 Validation loss: 2455.057373046875 best Validation loss: 2439.879150390625\n",
      "Epoch: 38700 Loss: 2588.33056640625 Validation loss: 2441.71435546875 best Validation loss: 2439.879150390625\n",
      "Epoch: 38800 Loss: 2604.055419921875 Validation loss: 2458.59619140625 best Validation loss: 2439.66455078125\n",
      "Epoch: 38900 Loss: 2600.49072265625 Validation loss: 2480.70458984375 best Validation loss: 2437.08447265625\n",
      "Epoch: 39000 Loss: 2585.08837890625 Validation loss: 2456.225830078125 best Validation loss: 2435.99365234375\n",
      "Epoch: 39100 Loss: 2595.509033203125 Validation loss: 2457.173583984375 best Validation loss: 2435.939697265625\n",
      "Epoch: 39200 Loss: 2609.931396484375 Validation loss: 2473.662353515625 best Validation loss: 2435.759033203125\n",
      "Epoch: 39300 Loss: 2581.926025390625 Validation loss: 2436.96044921875 best Validation loss: 2435.6787109375\n",
      "Epoch: 39400 Loss: 2580.4951171875 Validation loss: 2437.00048828125 best Validation loss: 2435.1328125\n",
      "Epoch: 39500 Loss: 2571.49755859375 Validation loss: 2436.344970703125 best Validation loss: 2434.717041015625\n",
      "Epoch: 39600 Loss: 2570.3037109375 Validation loss: 2437.14208984375 best Validation loss: 2434.35009765625\n",
      "Epoch: 39700 Loss: 2570.129638671875 Validation loss: 2435.32568359375 best Validation loss: 2434.083984375\n",
      "Epoch: 39800 Loss: 2586.33056640625 Validation loss: 2441.856689453125 best Validation loss: 2433.488525390625\n",
      "Epoch: 39900 Loss: 2570.061767578125 Validation loss: 2435.427978515625 best Validation loss: 2433.488525390625\n",
      "Epoch: 40000 Loss: 2567.658447265625 Validation loss: 2435.17822265625 best Validation loss: 2433.274169921875\n",
      "Epoch: 40100 Loss: 2602.759033203125 Validation loss: 2478.160400390625 best Validation loss: 2433.107666015625\n",
      "Epoch: 40200 Loss: 2602.219970703125 Validation loss: 2453.886962890625 best Validation loss: 2432.0986328125\n",
      "Epoch: 40300 Loss: 2566.6728515625 Validation loss: 2436.87646484375 best Validation loss: 2432.0986328125\n",
      "Epoch: 40400 Loss: 2560.2041015625 Validation loss: 2432.71728515625 best Validation loss: 2431.830810546875\n",
      "Epoch: 40500 Loss: 2600.033447265625 Validation loss: 2487.183349609375 best Validation loss: 2431.216064453125\n",
      "Epoch: 40600 Loss: 2602.29541015625 Validation loss: 2480.85400390625 best Validation loss: 2431.1787109375\n",
      "Epoch: 40700 Loss: 2559.764892578125 Validation loss: 2431.33740234375 best Validation loss: 2430.91455078125\n",
      "Epoch: 40800 Loss: 2556.063232421875 Validation loss: 2432.024169921875 best Validation loss: 2430.91455078125\n",
      "Epoch: 40900 Loss: 2597.67041015625 Validation loss: 2468.54150390625 best Validation loss: 2430.456787109375\n",
      "Epoch: 41000 Loss: 2604.40478515625 Validation loss: 2477.361328125 best Validation loss: 2430.373291015625\n",
      "Epoch: 41100 Loss: 2553.43212890625 Validation loss: 2436.654541015625 best Validation loss: 2429.5654296875\n",
      "Epoch: 41200 Loss: 2552.221923828125 Validation loss: 2430.85302734375 best Validation loss: 2429.278076171875\n",
      "Epoch: 41300 Loss: 2595.822509765625 Validation loss: 2469.137939453125 best Validation loss: 2429.278076171875\n",
      "Epoch: 41400 Loss: 2565.0029296875 Validation loss: 2436.74072265625 best Validation loss: 2428.984130859375\n",
      "Epoch: 41500 Loss: 2548.348388671875 Validation loss: 2434.80224609375 best Validation loss: 2428.875732421875\n",
      "Epoch: 41600 Loss: 2581.1044921875 Validation loss: 2464.06005859375 best Validation loss: 2428.14794921875\n",
      "Epoch: 41700 Loss: 2546.97802734375 Validation loss: 2430.947998046875 best Validation loss: 2428.14794921875\n",
      "Epoch: 41800 Loss: 2543.1240234375 Validation loss: 2430.173828125 best Validation loss: 2428.096435546875\n",
      "Epoch: 41900 Loss: 2543.515869140625 Validation loss: 2434.151611328125 best Validation loss: 2427.580810546875\n",
      "Epoch: 42000 Loss: 2581.253173828125 Validation loss: 2470.814453125 best Validation loss: 2427.580810546875\n",
      "Epoch: 42100 Loss: 2559.942626953125 Validation loss: 2434.4033203125 best Validation loss: 2427.485107421875\n",
      "Epoch: 42200 Loss: 2539.4287109375 Validation loss: 2428.15283203125 best Validation loss: 2426.941162109375\n",
      "Epoch: 42300 Loss: 2570.574462890625 Validation loss: 2483.675537109375 best Validation loss: 2426.77294921875\n",
      "Epoch: 42400 Loss: 2538.045166015625 Validation loss: 2432.73095703125 best Validation loss: 2426.220947265625\n",
      "Epoch: 42500 Loss: 2542.022216796875 Validation loss: 2444.17236328125 best Validation loss: 2426.220947265625\n",
      "Epoch: 42600 Loss: 2580.944580078125 Validation loss: 2491.775634765625 best Validation loss: 2426.220947265625\n",
      "Epoch: 42700 Loss: 2552.26318359375 Validation loss: 2435.008544921875 best Validation loss: 2426.15625\n",
      "Epoch: 42800 Loss: 2532.30712890625 Validation loss: 2430.202880859375 best Validation loss: 2425.780517578125\n",
      "Epoch: 42900 Loss: 2530.632568359375 Validation loss: 2430.066650390625 best Validation loss: 2425.780517578125\n",
      "Epoch: 43000 Loss: 2545.896484375 Validation loss: 2432.266845703125 best Validation loss: 2425.56396484375\n",
      "Epoch: 43100 Loss: 2536.87890625 Validation loss: 2436.759765625 best Validation loss: 2425.269287109375\n",
      "Epoch: 43200 Loss: 2542.494873046875 Validation loss: 2443.017822265625 best Validation loss: 2424.613037109375\n",
      "Epoch: 43300 Loss: 2531.836669921875 Validation loss: 2432.5361328125 best Validation loss: 2424.613037109375\n",
      "Epoch: 43400 Loss: 2531.7783203125 Validation loss: 2432.905029296875 best Validation loss: 2424.41015625\n",
      "Epoch: 43500 Loss: 2523.427734375 Validation loss: 2426.721435546875 best Validation loss: 2423.63818359375\n",
      "Epoch: 43600 Loss: 2529.90625 Validation loss: 2433.751953125 best Validation loss: 2423.63818359375\n",
      "Epoch: 43700 Loss: 2522.484619140625 Validation loss: 2424.352294921875 best Validation loss: 2423.63818359375\n",
      "Epoch: 43800 Loss: 2555.22119140625 Validation loss: 2460.357421875 best Validation loss: 2423.63818359375\n",
      "Epoch: 43900 Loss: 2520.913818359375 Validation loss: 2430.033935546875 best Validation loss: 2423.63818359375\n",
      "Epoch: 44000 Loss: 2521.281005859375 Validation loss: 2427.620361328125 best Validation loss: 2423.569580078125\n",
      "Epoch: 44100 Loss: 2576.885009765625 Validation loss: 2466.031494140625 best Validation loss: 2423.47607421875\n",
      "Epoch: 44200 Loss: 2560.09375 Validation loss: 2473.81201171875 best Validation loss: 2422.817138671875\n",
      "Epoch: 44300 Loss: 2514.8955078125 Validation loss: 2424.7763671875 best Validation loss: 2422.817138671875\n",
      "Epoch: 44400 Loss: 2539.127685546875 Validation loss: 2437.839111328125 best Validation loss: 2422.69921875\n",
      "Epoch: 44500 Loss: 2548.784423828125 Validation loss: 2448.912841796875 best Validation loss: 2422.69921875\n",
      "Epoch: 44600 Loss: 2567.580078125 Validation loss: 2484.7041015625 best Validation loss: 2422.685791015625\n",
      "Epoch: 44700 Loss: 2534.866455078125 Validation loss: 2461.926513671875 best Validation loss: 2422.20849609375\n",
      "Epoch: 44800 Loss: 2526.498291015625 Validation loss: 2453.664794921875 best Validation loss: 2422.20849609375\n",
      "Epoch: 44900 Loss: 2511.5341796875 Validation loss: 2432.13037109375 best Validation loss: 2422.20849609375\n",
      "Epoch: 45000 Loss: 2509.2890625 Validation loss: 2425.265869140625 best Validation loss: 2421.7373046875\n",
      "Epoch: 45100 Loss: 2515.703125 Validation loss: 2425.2021484375 best Validation loss: 2421.7373046875\n",
      "Epoch: 45200 Loss: 2538.555419921875 Validation loss: 2439.65185546875 best Validation loss: 2419.922607421875\n",
      "Epoch: 45300 Loss: 2502.770263671875 Validation loss: 2424.168212890625 best Validation loss: 2419.922607421875\n",
      "Epoch: 45400 Loss: 2526.628173828125 Validation loss: 2445.34521484375 best Validation loss: 2419.922607421875\n",
      "Epoch: 45500 Loss: 2510.35205078125 Validation loss: 2445.847900390625 best Validation loss: 2419.922607421875\n",
      "Epoch: 45600 Loss: 2540.778076171875 Validation loss: 2488.6875 best Validation loss: 2419.922607421875\n",
      "Epoch: 45700 Loss: 2500.7197265625 Validation loss: 2431.53515625 best Validation loss: 2419.922607421875\n",
      "Epoch: 45800 Loss: 2500.608154296875 Validation loss: 2427.1015625 best Validation loss: 2419.922607421875\n",
      "Epoch: 45900 Loss: 2537.285888671875 Validation loss: 2449.424072265625 best Validation loss: 2419.922607421875\n",
      "Epoch: 46000 Loss: 2499.76171875 Validation loss: 2427.3720703125 best Validation loss: 2419.82470703125\n",
      "Epoch: 46100 Loss: 2496.47412109375 Validation loss: 2420.84228515625 best Validation loss: 2419.82470703125\n",
      "Epoch: 46200 Loss: 2526.453857421875 Validation loss: 2476.931396484375 best Validation loss: 2419.79296875\n",
      "Epoch: 46300 Loss: 2491.15771484375 Validation loss: 2421.904541015625 best Validation loss: 2419.275390625\n",
      "Epoch: 46400 Loss: 2495.103271484375 Validation loss: 2429.485107421875 best Validation loss: 2419.275390625\n",
      "Epoch: 46500 Loss: 2527.232421875 Validation loss: 2462.4921875 best Validation loss: 2419.275390625\n",
      "Epoch: 46600 Loss: 2489.50341796875 Validation loss: 2422.619140625 best Validation loss: 2419.1923828125\n",
      "Epoch: 46700 Loss: 2529.923583984375 Validation loss: 2475.364501953125 best Validation loss: 2419.1923828125\n",
      "Epoch: 46800 Loss: 2541.676513671875 Validation loss: 2454.48095703125 best Validation loss: 2419.003662109375\n",
      "Epoch: 46900 Loss: 2488.17626953125 Validation loss: 2432.07421875 best Validation loss: 2418.73974609375\n",
      "Epoch: 47000 Loss: 2483.453857421875 Validation loss: 2419.918701171875 best Validation loss: 2418.695556640625\n",
      "Epoch: 47100 Loss: 2524.7470703125 Validation loss: 2443.01171875 best Validation loss: 2418.169189453125\n",
      "Epoch: 47200 Loss: 2487.440185546875 Validation loss: 2425.74365234375 best Validation loss: 2418.169189453125\n",
      "Epoch: 47300 Loss: 2517.683837890625 Validation loss: 2451.7763671875 best Validation loss: 2418.169189453125\n",
      "Epoch: 47400 Loss: 2481.549072265625 Validation loss: 2420.635986328125 best Validation loss: 2418.169189453125\n",
      "Epoch: 47500 Loss: 2491.20654296875 Validation loss: 2433.218994140625 best Validation loss: 2417.831787109375\n",
      "Epoch: 47600 Loss: 2489.7119140625 Validation loss: 2429.970458984375 best Validation loss: 2417.71484375\n",
      "Epoch: 47700 Loss: 2475.859619140625 Validation loss: 2419.857421875 best Validation loss: 2417.71484375\n",
      "Epoch: 47800 Loss: 2516.089599609375 Validation loss: 2468.517578125 best Validation loss: 2417.71484375\n",
      "Epoch: 47900 Loss: 2511.147216796875 Validation loss: 2435.354736328125 best Validation loss: 2417.71484375\n",
      "Epoch: 48000 Loss: 2512.35400390625 Validation loss: 2468.164306640625 best Validation loss: 2417.672119140625\n",
      "Epoch: 48100 Loss: 2472.169677734375 Validation loss: 2417.981201171875 best Validation loss: 2417.301025390625\n",
      "Epoch: 48200 Loss: 2475.61376953125 Validation loss: 2423.269287109375 best Validation loss: 2417.28857421875\n",
      "Epoch: 48300 Loss: 2476.656005859375 Validation loss: 2424.317626953125 best Validation loss: 2417.28857421875\n",
      "Epoch: 48400 Loss: 2485.660400390625 Validation loss: 2433.842041015625 best Validation loss: 2417.2626953125\n",
      "Epoch: 48500 Loss: 2474.498046875 Validation loss: 2424.392578125 best Validation loss: 2417.05810546875\n",
      "Epoch: 48600 Loss: 2485.990478515625 Validation loss: 2440.068115234375 best Validation loss: 2416.73193359375\n",
      "Epoch: 48700 Loss: 2473.6650390625 Validation loss: 2436.8544921875 best Validation loss: 2416.41552734375\n",
      "Epoch: 48800 Loss: 2481.263427734375 Validation loss: 2422.5908203125 best Validation loss: 2416.41552734375\n",
      "Epoch: 48900 Loss: 2463.143798828125 Validation loss: 2418.662841796875 best Validation loss: 2416.334228515625\n",
      "Epoch: 49000 Loss: 2512.4140625 Validation loss: 2474.8017578125 best Validation loss: 2415.730712890625\n",
      "Epoch: 49100 Loss: 2462.841796875 Validation loss: 2423.2265625 best Validation loss: 2415.730712890625\n",
      "Epoch: 49200 Loss: 2463.574951171875 Validation loss: 2427.06005859375 best Validation loss: 2415.730712890625\n",
      "Epoch: 49300 Loss: 2498.566650390625 Validation loss: 2447.067138671875 best Validation loss: 2415.730712890625\n",
      "Epoch: 49400 Loss: 2469.27880859375 Validation loss: 2422.476318359375 best Validation loss: 2414.9755859375\n",
      "Epoch: 49500 Loss: 2464.490234375 Validation loss: 2419.029541015625 best Validation loss: 2414.9755859375\n",
      "Epoch: 49600 Loss: 2482.53662109375 Validation loss: 2431.18798828125 best Validation loss: 2414.9755859375\n",
      "Epoch: 49700 Loss: 2457.63623046875 Validation loss: 2417.20458984375 best Validation loss: 2414.9755859375\n",
      "Epoch: 49800 Loss: 2454.72265625 Validation loss: 2415.936767578125 best Validation loss: 2414.9755859375\n",
      "Epoch: 49900 Loss: 2517.491455078125 Validation loss: 2467.376708984375 best Validation loss: 2414.904541015625\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_val_loss = float('inf')\n",
    "training_loss = np.array([])\n",
    "validation_loss = np.array([])\n",
    "last_val_loss = float('inf')\n",
    "count = 0\n",
    "\n",
    "for n in range(NUMBER_OF_EPOCH):\n",
    "    model.train()\n",
    "    y_pred = model(X_train)[:, 0]\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    training_loss = np.append(training_loss, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = model(X_val)[:, 0]\n",
    "    val_loss = loss_fn(y_pred, y_val)\n",
    "    validation_loss = np.append(validation_loss, val_loss.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model, 'mlp_model.pth')\n",
    "    \n",
    "    if n % 100 == 0:\n",
    "        print(f'Epoch: {n} Loss: {loss.item()}'f' Validation loss: {val_loss.item()}'f' best Validation loss: {best_val_loss}')\n",
    "        \n",
    "    if last_val_loss < val_loss:\n",
    "        count += 1\n",
    "        if count == 25:\n",
    "            break\n",
    "    else:\n",
    "        count = 0\n",
    "    last_val_loss = val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x31b473fd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/cy9kvd894_bfkfb71dsbxt2w0000gn/T/ipykernel_10139/3527652370.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('mlp_model.pth')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "df = pd.read_csv('data/test.csv')\n",
    "model = torch.load('mlp_model.pth')\n",
    "model.eval()\n",
    "\n",
    "index = df['id']\n",
    "df = df.drop(['id'], axis=1)\n",
    "X = pre.encoder(df)\n",
    "# X = pre.standardize(X, scaler=pickle.load(open('scaler.pkl', 'rb')))\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_pred = model(X)[:, 0]\n",
    "\n",
    "df = pd.DataFrame(y_pred.detach().numpy(), columns=['price'])\n",
    "df = pd.concat([index, df], axis=1)\n",
    "df.rename(columns={'price': 'answer'}, inplace=True)\n",
    "df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
