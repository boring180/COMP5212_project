{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_EPOCH = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import preprossesing as pre\n",
    "import math\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(df):\n",
    "    \n",
    "    df = pre.standardize(df)\n",
    "    df = pre.encoder(df)\n",
    "    df = df.drop(['id'], axis=1)\n",
    "\n",
    "    train, val = pre.test_validation_split(df)\n",
    "    \n",
    "    y_train = torch.tensor(train['price'].values, dtype=torch.float32)\n",
    "    X_train = train.drop(['price'], axis=1)\n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    \n",
    "    y_val = torch.tensor(val['price'].values, dtype=torch.float32)\n",
    "    X_val = val.drop(['price'], axis=1)\n",
    "    X_val = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlp(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=175, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mlp, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "        nn.Linear(175, 128),\n",
    "        nn.ReLU(), \n",
    "        \n",
    "        nn.Linear(128, 1) \n",
    "        )\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return self.layers(x)\n",
    "\n",
    "model = mlp()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss, self).__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(self.mse(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = RMSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "X_train, y_train, X_val, y_val = prepare_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 18202.3828125 Validation loss: 17929.712890625 best Validation loss: 17929.712890625\n",
      "Epoch: 100 Loss: 18193.173828125 Validation loss: 17920.44921875 best Validation loss: 17920.44921875\n",
      "Epoch: 200 Loss: 18160.3828125 Validation loss: 17887.771484375 best Validation loss: 17887.771484375\n",
      "Epoch: 300 Loss: 18100.349609375 Validation loss: 17828.158203125 best Validation loss: 17828.158203125\n",
      "Epoch: 400 Loss: 18012.55078125 Validation loss: 17741.0859375 best Validation loss: 17741.0859375\n",
      "Epoch: 500 Loss: 17898.94140625 Validation loss: 17628.529296875 best Validation loss: 17628.529296875\n",
      "Epoch: 600 Loss: 17761.462890625 Validation loss: 17492.384765625 best Validation loss: 17492.384765625\n",
      "Epoch: 700 Loss: 17601.314453125 Validation loss: 17333.8359375 best Validation loss: 17333.8359375\n",
      "Epoch: 800 Loss: 17419.546875 Validation loss: 17153.919921875 best Validation loss: 17153.919921875\n",
      "Epoch: 900 Loss: 17216.927734375 Validation loss: 16953.376953125 best Validation loss: 16953.376953125\n",
      "Epoch: 1000 Loss: 16992.849609375 Validation loss: 16731.61328125 best Validation loss: 16731.61328125\n",
      "Epoch: 1100 Loss: 16749.3125 Validation loss: 16490.611328125 best Validation loss: 16490.611328125\n",
      "Epoch: 1200 Loss: 16487.552734375 Validation loss: 16231.583984375 best Validation loss: 16231.583984375\n",
      "Epoch: 1300 Loss: 16208.5234375 Validation loss: 15955.46484375 best Validation loss: 15955.46484375\n",
      "Epoch: 1400 Loss: 15913.1279296875 Validation loss: 15663.14453125 best Validation loss: 15663.14453125\n",
      "Epoch: 1500 Loss: 15602.2587890625 Validation loss: 15355.49609375 best Validation loss: 15355.49609375\n",
      "Epoch: 1600 Loss: 15276.806640625 Validation loss: 15033.396484375 best Validation loss: 15033.396484375\n",
      "Epoch: 1700 Loss: 14937.6787109375 Validation loss: 14697.736328125 best Validation loss: 14697.736328125\n",
      "Epoch: 1800 Loss: 14585.8125 Validation loss: 14349.431640625 best Validation loss: 14349.431640625\n",
      "Epoch: 1900 Loss: 14222.177734375 Validation loss: 13989.439453125 best Validation loss: 13989.439453125\n",
      "Epoch: 2000 Loss: 13847.7958984375 Validation loss: 13618.7568359375 best Validation loss: 13618.7568359375\n",
      "Epoch: 2100 Loss: 13463.751953125 Validation loss: 13238.4462890625 best Validation loss: 13238.4462890625\n",
      "Epoch: 2200 Loss: 13071.2041015625 Validation loss: 12849.64453125 best Validation loss: 12849.64453125\n",
      "Epoch: 2300 Loss: 12671.4072265625 Validation loss: 12453.580078125 best Validation loss: 12453.580078125\n",
      "Epoch: 2400 Loss: 12265.7197265625 Validation loss: 12051.5869140625 best Validation loss: 12051.5869140625\n",
      "Epoch: 2500 Loss: 11855.6259765625 Validation loss: 11645.1171875 best Validation loss: 11645.1171875\n",
      "Epoch: 2600 Loss: 11442.748046875 Validation loss: 11235.7578125 best Validation loss: 11235.7578125\n",
      "Epoch: 2700 Loss: 11028.8544921875 Validation loss: 10825.240234375 best Validation loss: 10825.240234375\n",
      "Epoch: 2800 Loss: 10615.861328125 Validation loss: 10415.4365234375 best Validation loss: 10415.4365234375\n",
      "Epoch: 2900 Loss: 10205.833984375 Validation loss: 10008.3544921875 best Validation loss: 10008.3544921875\n",
      "Epoch: 3000 Loss: 9800.9462890625 Validation loss: 9606.1171875 best Validation loss: 9606.1171875\n",
      "Epoch: 3100 Loss: 9403.4697265625 Validation loss: 9210.9443359375 best Validation loss: 9210.9443359375\n",
      "Epoch: 3200 Loss: 9015.7138671875 Validation loss: 8825.060546875 best Validation loss: 8825.060546875\n",
      "Epoch: 3300 Loss: 8639.9326171875 Validation loss: 8450.6318359375 best Validation loss: 8450.6318359375\n",
      "Epoch: 3400 Loss: 8278.2275390625 Validation loss: 8089.7021484375 best Validation loss: 8089.7021484375\n",
      "Epoch: 3500 Loss: 7932.2724609375 Validation loss: 7743.90771484375 best Validation loss: 7743.90771484375\n",
      "Epoch: 3600 Loss: 7603.05126953125 Validation loss: 7414.17333984375 best Validation loss: 7414.17333984375\n",
      "Epoch: 3700 Loss: 7290.732421875 Validation loss: 7100.6728515625 best Validation loss: 7100.6728515625\n",
      "Epoch: 3800 Loss: 6995.0009765625 Validation loss: 6803.15771484375 best Validation loss: 6803.15771484375\n",
      "Epoch: 3900 Loss: 6715.14990234375 Validation loss: 6521.0185546875 best Validation loss: 6521.0185546875\n",
      "Epoch: 4000 Loss: 6450.1044921875 Validation loss: 6253.29052734375 best Validation loss: 6253.29052734375\n",
      "Epoch: 4100 Loss: 6198.455078125 Validation loss: 5998.6943359375 best Validation loss: 5998.6943359375\n",
      "Epoch: 4200 Loss: 5958.36767578125 Validation loss: 5755.38134765625 best Validation loss: 5755.38134765625\n",
      "Epoch: 4300 Loss: 5729.01611328125 Validation loss: 5522.58837890625 best Validation loss: 5522.58837890625\n",
      "Epoch: 4400 Loss: 5509.2373046875 Validation loss: 5299.16748046875 best Validation loss: 5299.16748046875\n",
      "Epoch: 4500 Loss: 5298.52490234375 Validation loss: 5084.8828125 best Validation loss: 5084.8828125\n",
      "Epoch: 4600 Loss: 5096.0908203125 Validation loss: 4879.26806640625 best Validation loss: 4879.26806640625\n",
      "Epoch: 4700 Loss: 4902.52490234375 Validation loss: 4682.9892578125 best Validation loss: 4682.9892578125\n",
      "Epoch: 4800 Loss: 4718.28857421875 Validation loss: 4496.45751953125 best Validation loss: 4496.45751953125\n",
      "Epoch: 4900 Loss: 4544.578125 Validation loss: 4320.7333984375 best Validation loss: 4320.7333984375\n",
      "Epoch: 5000 Loss: 4382.12109375 Validation loss: 4156.61962890625 best Validation loss: 4156.61962890625\n",
      "Epoch: 5100 Loss: 4230.78515625 Validation loss: 4004.019775390625 best Validation loss: 4004.019775390625\n",
      "Epoch: 5200 Loss: 4090.44287109375 Validation loss: 3862.85400390625 best Validation loss: 3862.85400390625\n",
      "Epoch: 5300 Loss: 3961.6123046875 Validation loss: 3733.650390625 best Validation loss: 3733.650390625\n",
      "Epoch: 5400 Loss: 3844.83056640625 Validation loss: 3616.98291015625 best Validation loss: 3616.98291015625\n",
      "Epoch: 5500 Loss: 3740.33349609375 Validation loss: 3513.021240234375 best Validation loss: 3513.021240234375\n",
      "Epoch: 5600 Loss: 3647.30224609375 Validation loss: 3420.90234375 best Validation loss: 3420.90234375\n",
      "Epoch: 5700 Loss: 3564.54833984375 Validation loss: 3339.5244140625 best Validation loss: 3339.5244140625\n",
      "Epoch: 5800 Loss: 3491.5205078125 Validation loss: 3268.3291015625 best Validation loss: 3268.3291015625\n",
      "Epoch: 5900 Loss: 3427.688232421875 Validation loss: 3206.7626953125 best Validation loss: 3206.7626953125\n",
      "Epoch: 6000 Loss: 3372.068115234375 Validation loss: 3153.788818359375 best Validation loss: 3153.788818359375\n",
      "Epoch: 6100 Loss: 3323.436279296875 Validation loss: 3108.0908203125 best Validation loss: 3108.0908203125\n",
      "Epoch: 6200 Loss: 3280.626708984375 Validation loss: 3068.392333984375 best Validation loss: 3068.392333984375\n",
      "Epoch: 6300 Loss: 3242.5283203125 Validation loss: 3033.490234375 best Validation loss: 3033.490234375\n",
      "Epoch: 6400 Loss: 3208.15283203125 Validation loss: 3002.458251953125 best Validation loss: 3002.458251953125\n",
      "Epoch: 6500 Loss: 3176.68603515625 Validation loss: 2974.431396484375 best Validation loss: 2974.431396484375\n",
      "Epoch: 6600 Loss: 3147.431396484375 Validation loss: 2948.71240234375 best Validation loss: 2948.71240234375\n",
      "Epoch: 6700 Loss: 3119.873291015625 Validation loss: 2924.7333984375 best Validation loss: 2924.7333984375\n",
      "Epoch: 6800 Loss: 3093.6279296875 Validation loss: 2902.119140625 best Validation loss: 2902.119140625\n",
      "Epoch: 6900 Loss: 3068.410400390625 Validation loss: 2880.532958984375 best Validation loss: 2880.532958984375\n",
      "Epoch: 7000 Loss: 3044.00634765625 Validation loss: 2859.75732421875 best Validation loss: 2859.75732421875\n",
      "Epoch: 7100 Loss: 3020.2421875 Validation loss: 2839.633056640625 best Validation loss: 2839.633056640625\n",
      "Epoch: 7200 Loss: 2997.040771484375 Validation loss: 2820.047119140625 best Validation loss: 2820.047119140625\n",
      "Epoch: 7300 Loss: 2974.315673828125 Validation loss: 2800.8759765625 best Validation loss: 2800.8759765625\n",
      "Epoch: 7400 Loss: 2952.035888671875 Validation loss: 2782.149169921875 best Validation loss: 2782.149169921875\n",
      "Epoch: 7500 Loss: 2930.16748046875 Validation loss: 2763.7998046875 best Validation loss: 2763.7998046875\n",
      "Epoch: 7600 Loss: 2908.690673828125 Validation loss: 2745.818359375 best Validation loss: 2745.818359375\n",
      "Epoch: 7700 Loss: 2887.582763671875 Validation loss: 2728.166259765625 best Validation loss: 2728.166259765625\n",
      "Epoch: 7800 Loss: 2866.83642578125 Validation loss: 2710.941162109375 best Validation loss: 2710.941162109375\n",
      "Epoch: 7900 Loss: 2846.4375 Validation loss: 2694.086669921875 best Validation loss: 2694.086669921875\n",
      "Epoch: 8000 Loss: 2826.38232421875 Validation loss: 2677.57958984375 best Validation loss: 2677.57958984375\n",
      "Epoch: 8100 Loss: 2806.6953125 Validation loss: 2661.4296875 best Validation loss: 2661.4296875\n",
      "Epoch: 8200 Loss: 2787.361572265625 Validation loss: 2645.6162109375 best Validation loss: 2645.6162109375\n",
      "Epoch: 8300 Loss: 2768.38525390625 Validation loss: 2630.209228515625 best Validation loss: 2630.209228515625\n",
      "Epoch: 8400 Loss: 2749.7890625 Validation loss: 2615.24169921875 best Validation loss: 2615.24169921875\n",
      "Epoch: 8500 Loss: 2731.553466796875 Validation loss: 2600.677978515625 best Validation loss: 2600.677978515625\n",
      "Epoch: 8600 Loss: 2713.650390625 Validation loss: 2586.4833984375 best Validation loss: 2586.4833984375\n",
      "Epoch: 8700 Loss: 2696.0576171875 Validation loss: 2572.668212890625 best Validation loss: 2572.668212890625\n",
      "Epoch: 8800 Loss: 2678.7548828125 Validation loss: 2559.1826171875 best Validation loss: 2559.1826171875\n",
      "Epoch: 8900 Loss: 2661.71240234375 Validation loss: 2545.98681640625 best Validation loss: 2545.98681640625\n",
      "Epoch: 9000 Loss: 2644.860107421875 Validation loss: 2532.994384765625 best Validation loss: 2532.994384765625\n",
      "Epoch: 9100 Loss: 2628.185791015625 Validation loss: 2520.156494140625 best Validation loss: 2520.156494140625\n",
      "Epoch: 9200 Loss: 2611.623046875 Validation loss: 2507.2998046875 best Validation loss: 2507.2998046875\n",
      "Epoch: 9300 Loss: 2595.081298828125 Validation loss: 2494.3603515625 best Validation loss: 2494.3603515625\n",
      "Epoch: 9400 Loss: 2578.508056640625 Validation loss: 2481.282470703125 best Validation loss: 2481.282470703125\n",
      "Epoch: 9500 Loss: 2561.84228515625 Validation loss: 2467.917724609375 best Validation loss: 2467.917724609375\n",
      "Epoch: 9600 Loss: 2544.98046875 Validation loss: 2454.1904296875 best Validation loss: 2454.1904296875\n",
      "Epoch: 9700 Loss: 2527.891357421875 Validation loss: 2440.182861328125 best Validation loss: 2440.182861328125\n",
      "Epoch: 9800 Loss: 2510.6357421875 Validation loss: 2425.935546875 best Validation loss: 2425.935546875\n",
      "Epoch: 9900 Loss: 2493.29150390625 Validation loss: 2411.553955078125 best Validation loss: 2411.553955078125\n",
      "Epoch: 10000 Loss: 2475.974853515625 Validation loss: 2397.274658203125 best Validation loss: 2397.274658203125\n",
      "Epoch: 10100 Loss: 2458.739013671875 Validation loss: 2383.141845703125 best Validation loss: 2383.141845703125\n",
      "Epoch: 10200 Loss: 2441.752685546875 Validation loss: 2369.389892578125 best Validation loss: 2369.389892578125\n",
      "Epoch: 10300 Loss: 2425.219482421875 Validation loss: 2356.1982421875 best Validation loss: 2356.1982421875\n",
      "Epoch: 10400 Loss: 2409.19482421875 Validation loss: 2343.628662109375 best Validation loss: 2343.628662109375\n",
      "Epoch: 10500 Loss: 2393.72705078125 Validation loss: 2331.776611328125 best Validation loss: 2331.776611328125\n",
      "Epoch: 10600 Loss: 2378.7939453125 Validation loss: 2320.71826171875 best Validation loss: 2320.71826171875\n",
      "Epoch: 10700 Loss: 2364.35888671875 Validation loss: 2310.34765625 best Validation loss: 2310.34765625\n",
      "Epoch: 10800 Loss: 2350.423095703125 Validation loss: 2300.681884765625 best Validation loss: 2300.681884765625\n",
      "Epoch: 10900 Loss: 2336.906005859375 Validation loss: 2291.6728515625 best Validation loss: 2291.6728515625\n",
      "Epoch: 11000 Loss: 2323.932861328125 Validation loss: 2283.172119140625 best Validation loss: 2283.172119140625\n",
      "Epoch: 11100 Loss: 2311.572998046875 Validation loss: 2275.1962890625 best Validation loss: 2275.1962890625\n",
      "Epoch: 11200 Loss: 2299.89990234375 Validation loss: 2267.734375 best Validation loss: 2267.734375\n",
      "Epoch: 11300 Loss: 2288.8232421875 Validation loss: 2260.660400390625 best Validation loss: 2260.660400390625\n",
      "Epoch: 11400 Loss: 2278.252685546875 Validation loss: 2253.8740234375 best Validation loss: 2253.8740234375\n",
      "Epoch: 11500 Loss: 2268.1630859375 Validation loss: 2247.23779296875 best Validation loss: 2247.23779296875\n",
      "Epoch: 11600 Loss: 2258.4541015625 Validation loss: 2240.710205078125 best Validation loss: 2240.710205078125\n",
      "Epoch: 11700 Loss: 2249.05615234375 Validation loss: 2234.25537109375 best Validation loss: 2234.25537109375\n",
      "Epoch: 11800 Loss: 2239.906494140625 Validation loss: 2227.83349609375 best Validation loss: 2227.83349609375\n",
      "Epoch: 11900 Loss: 2230.9853515625 Validation loss: 2221.444091796875 best Validation loss: 2221.444091796875\n",
      "Epoch: 12000 Loss: 2222.250732421875 Validation loss: 2215.059326171875 best Validation loss: 2215.059326171875\n",
      "Epoch: 12100 Loss: 2213.678466796875 Validation loss: 2208.606201171875 best Validation loss: 2208.606201171875\n",
      "Epoch: 12200 Loss: 2205.263427734375 Validation loss: 2201.992431640625 best Validation loss: 2201.992431640625\n",
      "Epoch: 12300 Loss: 2196.937744140625 Validation loss: 2195.298095703125 best Validation loss: 2195.298095703125\n",
      "Epoch: 12400 Loss: 2188.677001953125 Validation loss: 2188.586181640625 best Validation loss: 2188.586181640625\n",
      "Epoch: 12500 Loss: 2180.4482421875 Validation loss: 2181.895263671875 best Validation loss: 2181.895263671875\n",
      "Epoch: 12600 Loss: 2172.2861328125 Validation loss: 2175.102783203125 best Validation loss: 2175.102783203125\n",
      "Epoch: 12700 Loss: 2164.22509765625 Validation loss: 2168.36865234375 best Validation loss: 2168.36865234375\n",
      "Epoch: 12800 Loss: 2156.204833984375 Validation loss: 2161.55126953125 best Validation loss: 2161.55126953125\n",
      "Epoch: 12900 Loss: 2148.242919921875 Validation loss: 2154.682373046875 best Validation loss: 2154.682373046875\n",
      "Epoch: 13000 Loss: 2140.37109375 Validation loss: 2147.695556640625 best Validation loss: 2147.695556640625\n",
      "Epoch: 13100 Loss: 2132.644775390625 Validation loss: 2140.7666015625 best Validation loss: 2140.7666015625\n",
      "Epoch: 13200 Loss: 2125.0986328125 Validation loss: 2133.891845703125 best Validation loss: 2133.891845703125\n",
      "Epoch: 13300 Loss: 2117.71435546875 Validation loss: 2127.2314453125 best Validation loss: 2127.2314453125\n",
      "Epoch: 13400 Loss: 2110.514892578125 Validation loss: 2120.746337890625 best Validation loss: 2120.746337890625\n",
      "Epoch: 13500 Loss: 2103.489501953125 Validation loss: 2114.524169921875 best Validation loss: 2114.524169921875\n",
      "Epoch: 13600 Loss: 2096.695068359375 Validation loss: 2108.615234375 best Validation loss: 2108.615234375\n",
      "Epoch: 13700 Loss: 2090.136962890625 Validation loss: 2102.972412109375 best Validation loss: 2102.972412109375\n",
      "Epoch: 13800 Loss: 2083.77197265625 Validation loss: 2097.484375 best Validation loss: 2097.484375\n",
      "Epoch: 13900 Loss: 2077.556884765625 Validation loss: 2092.137939453125 best Validation loss: 2092.137939453125\n",
      "Epoch: 14000 Loss: 2071.52490234375 Validation loss: 2086.931640625 best Validation loss: 2086.931640625\n",
      "Epoch: 14100 Loss: 2065.69873046875 Validation loss: 2081.948974609375 best Validation loss: 2081.948974609375\n",
      "Epoch: 14200 Loss: 2060.02587890625 Validation loss: 2077.1240234375 best Validation loss: 2077.1240234375\n",
      "Epoch: 14300 Loss: 2054.515625 Validation loss: 2072.46337890625 best Validation loss: 2072.46337890625\n",
      "Epoch: 14400 Loss: 2049.1474609375 Validation loss: 2067.974609375 best Validation loss: 2067.974609375\n",
      "Epoch: 14500 Loss: 2043.8935546875 Validation loss: 2063.742919921875 best Validation loss: 2063.742919921875\n",
      "Epoch: 14600 Loss: 2038.7506103515625 Validation loss: 2059.7109375 best Validation loss: 2059.7109375\n",
      "Epoch: 14700 Loss: 2033.6973876953125 Validation loss: 2055.81396484375 best Validation loss: 2055.81396484375\n",
      "Epoch: 14800 Loss: 2028.769775390625 Validation loss: 2052.110107421875 best Validation loss: 2052.110107421875\n",
      "Epoch: 14900 Loss: 2023.9683837890625 Validation loss: 2048.560302734375 best Validation loss: 2048.560302734375\n",
      "Epoch: 15000 Loss: 2019.2474365234375 Validation loss: 2045.1956787109375 best Validation loss: 2045.1956787109375\n",
      "Epoch: 15100 Loss: 2014.5552978515625 Validation loss: 2041.9766845703125 best Validation loss: 2041.9766845703125\n",
      "Epoch: 15200 Loss: 2009.86376953125 Validation loss: 2038.8486328125 best Validation loss: 2038.8486328125\n",
      "Epoch: 15300 Loss: 2005.24462890625 Validation loss: 2035.6673583984375 best Validation loss: 2035.6673583984375\n",
      "Epoch: 15400 Loss: 2000.670654296875 Validation loss: 2032.5955810546875 best Validation loss: 2032.5955810546875\n",
      "Epoch: 15500 Loss: 1996.125244140625 Validation loss: 2029.565185546875 best Validation loss: 2029.565185546875\n",
      "Epoch: 15600 Loss: 1991.571533203125 Validation loss: 2026.57421875 best Validation loss: 2026.57421875\n",
      "Epoch: 15700 Loss: 1987.06689453125 Validation loss: 2023.8834228515625 best Validation loss: 2023.8834228515625\n",
      "Epoch: 15800 Loss: 1982.5758056640625 Validation loss: 2021.3162841796875 best Validation loss: 2021.3162841796875\n",
      "Epoch: 15900 Loss: 1978.1766357421875 Validation loss: 2018.98046875 best Validation loss: 2018.98046875\n",
      "Epoch: 16000 Loss: 1973.813232421875 Validation loss: 2016.7625732421875 best Validation loss: 2016.7625732421875\n",
      "Epoch: 16100 Loss: 1969.5367431640625 Validation loss: 2014.552001953125 best Validation loss: 2014.552001953125\n",
      "Epoch: 16200 Loss: 1965.1978759765625 Validation loss: 2012.3680419921875 best Validation loss: 2012.3680419921875\n",
      "Epoch: 16300 Loss: 1960.8988037109375 Validation loss: 2010.2919921875 best Validation loss: 2010.2919921875\n",
      "Epoch: 16400 Loss: 1956.6298828125 Validation loss: 2008.2647705078125 best Validation loss: 2008.2647705078125\n",
      "Epoch: 16500 Loss: 1952.3939208984375 Validation loss: 2006.16650390625 best Validation loss: 2006.16650390625\n",
      "Epoch: 16600 Loss: 1948.183837890625 Validation loss: 2004.1444091796875 best Validation loss: 2004.1444091796875\n",
      "Epoch: 16700 Loss: 1944.0040283203125 Validation loss: 2002.0389404296875 best Validation loss: 2002.0389404296875\n",
      "Epoch: 16800 Loss: 1939.827392578125 Validation loss: 1999.8388671875 best Validation loss: 1999.8388671875\n",
      "Epoch: 16900 Loss: 1935.666015625 Validation loss: 1997.3782958984375 best Validation loss: 1997.3782958984375\n",
      "Epoch: 17000 Loss: 1931.5269775390625 Validation loss: 1994.8646240234375 best Validation loss: 1994.8646240234375\n",
      "Epoch: 17100 Loss: 1927.41015625 Validation loss: 1992.189208984375 best Validation loss: 1992.189208984375\n",
      "Epoch: 17200 Loss: 1923.260009765625 Validation loss: 1989.419189453125 best Validation loss: 1989.419189453125\n",
      "Epoch: 17300 Loss: 1919.0914306640625 Validation loss: 1986.6357421875 best Validation loss: 1986.6357421875\n",
      "Epoch: 17400 Loss: 1914.9072265625 Validation loss: 1983.69775390625 best Validation loss: 1983.69775390625\n",
      "Epoch: 17500 Loss: 1910.659423828125 Validation loss: 1980.7366943359375 best Validation loss: 1980.7366943359375\n",
      "Epoch: 17600 Loss: 1906.316650390625 Validation loss: 1977.79736328125 best Validation loss: 1977.79736328125\n",
      "Epoch: 17700 Loss: 1901.933837890625 Validation loss: 1974.855712890625 best Validation loss: 1974.855712890625\n",
      "Epoch: 17800 Loss: 1897.53125 Validation loss: 1971.94580078125 best Validation loss: 1971.94580078125\n",
      "Epoch: 17900 Loss: 1893.1583251953125 Validation loss: 1968.9932861328125 best Validation loss: 1968.9932861328125\n",
      "Epoch: 18000 Loss: 1888.799560546875 Validation loss: 1966.05126953125 best Validation loss: 1966.05126953125\n",
      "Epoch: 18100 Loss: 1884.4210205078125 Validation loss: 1963.07568359375 best Validation loss: 1963.07568359375\n",
      "Epoch: 18200 Loss: 1879.985595703125 Validation loss: 1960.0460205078125 best Validation loss: 1960.0460205078125\n",
      "Epoch: 18300 Loss: 1875.5233154296875 Validation loss: 1957.0240478515625 best Validation loss: 1957.0240478515625\n",
      "Epoch: 18400 Loss: 1871.0469970703125 Validation loss: 1953.9814453125 best Validation loss: 1953.9814453125\n",
      "Epoch: 18500 Loss: 1866.6595458984375 Validation loss: 1951.183349609375 best Validation loss: 1951.183349609375\n",
      "Epoch: 18600 Loss: 1862.2655029296875 Validation loss: 1948.6195068359375 best Validation loss: 1948.6195068359375\n",
      "Epoch: 18700 Loss: 1857.935302734375 Validation loss: 1946.2294921875 best Validation loss: 1946.2294921875\n",
      "Epoch: 18800 Loss: 1853.6558837890625 Validation loss: 1943.882080078125 best Validation loss: 1943.882080078125\n",
      "Epoch: 18900 Loss: 1849.4398193359375 Validation loss: 1941.6026611328125 best Validation loss: 1941.6026611328125\n",
      "Epoch: 19000 Loss: 1845.263916015625 Validation loss: 1939.3095703125 best Validation loss: 1939.3095703125\n",
      "Epoch: 19100 Loss: 1841.1053466796875 Validation loss: 1937.1396484375 best Validation loss: 1937.1396484375\n",
      "Epoch: 19200 Loss: 1836.953369140625 Validation loss: 1934.9873046875 best Validation loss: 1934.9873046875\n",
      "Epoch: 19300 Loss: 1832.820068359375 Validation loss: 1932.862060546875 best Validation loss: 1932.862060546875\n",
      "Epoch: 19400 Loss: 1828.7257080078125 Validation loss: 1930.89306640625 best Validation loss: 1930.89306640625\n",
      "Epoch: 19500 Loss: 1824.695068359375 Validation loss: 1928.9593505859375 best Validation loss: 1928.9593505859375\n",
      "Epoch: 19600 Loss: 1820.7152099609375 Validation loss: 1927.1134033203125 best Validation loss: 1927.1134033203125\n",
      "Epoch: 19700 Loss: 1816.782958984375 Validation loss: 1925.343017578125 best Validation loss: 1925.343017578125\n",
      "Epoch: 19800 Loss: 1812.91748046875 Validation loss: 1923.53759765625 best Validation loss: 1923.53759765625\n",
      "Epoch: 19900 Loss: 1809.109130859375 Validation loss: 1921.611572265625 best Validation loss: 1921.611572265625\n",
      "Epoch: 20000 Loss: 1805.334228515625 Validation loss: 1919.7303466796875 best Validation loss: 1919.7303466796875\n",
      "Epoch: 20100 Loss: 1801.562255859375 Validation loss: 1917.785888671875 best Validation loss: 1917.785888671875\n",
      "Epoch: 20200 Loss: 1797.844482421875 Validation loss: 1915.9542236328125 best Validation loss: 1915.9542236328125\n",
      "Epoch: 20300 Loss: 1794.2415771484375 Validation loss: 1914.1513671875 best Validation loss: 1914.1513671875\n",
      "Epoch: 20400 Loss: 1790.673095703125 Validation loss: 1912.3843994140625 best Validation loss: 1912.3843994140625\n",
      "Epoch: 20500 Loss: 1787.1265869140625 Validation loss: 1910.697021484375 best Validation loss: 1910.697021484375\n",
      "Epoch: 20600 Loss: 1783.6513671875 Validation loss: 1909.141845703125 best Validation loss: 1909.141845703125\n",
      "Epoch: 20700 Loss: 1780.230712890625 Validation loss: 1907.5052490234375 best Validation loss: 1907.5052490234375\n",
      "Epoch: 20800 Loss: 1776.8817138671875 Validation loss: 1905.76416015625 best Validation loss: 1905.76416015625\n",
      "Epoch: 20900 Loss: 1773.5445556640625 Validation loss: 1903.9453125 best Validation loss: 1903.9453125\n",
      "Epoch: 21000 Loss: 1770.2222900390625 Validation loss: 1902.19287109375 best Validation loss: 1902.19287109375\n",
      "Epoch: 21100 Loss: 1766.8992919921875 Validation loss: 1900.4615478515625 best Validation loss: 1900.4615478515625\n",
      "Epoch: 21200 Loss: 1763.5997314453125 Validation loss: 1898.6431884765625 best Validation loss: 1898.6431884765625\n",
      "Epoch: 21300 Loss: 1760.326904296875 Validation loss: 1896.7606201171875 best Validation loss: 1896.7606201171875\n",
      "Epoch: 21400 Loss: 1757.0789794921875 Validation loss: 1894.987548828125 best Validation loss: 1894.987548828125\n",
      "Epoch: 21500 Loss: 1753.85107421875 Validation loss: 1893.263671875 best Validation loss: 1893.263671875\n",
      "Epoch: 21600 Loss: 1750.680908203125 Validation loss: 1891.689453125 best Validation loss: 1891.689453125\n",
      "Epoch: 21700 Loss: 1747.54345703125 Validation loss: 1890.1220703125 best Validation loss: 1890.1220703125\n",
      "Epoch: 21800 Loss: 1744.4207763671875 Validation loss: 1888.526611328125 best Validation loss: 1888.526611328125\n",
      "Epoch: 21900 Loss: 1741.316162109375 Validation loss: 1886.9893798828125 best Validation loss: 1886.9893798828125\n",
      "Epoch: 22000 Loss: 1738.23291015625 Validation loss: 1885.6910400390625 best Validation loss: 1885.6910400390625\n",
      "Epoch: 22100 Loss: 1735.1650390625 Validation loss: 1884.47607421875 best Validation loss: 1884.47607421875\n",
      "Epoch: 22200 Loss: 1732.137451171875 Validation loss: 1883.17626953125 best Validation loss: 1883.17626953125\n",
      "Epoch: 22300 Loss: 1729.1876220703125 Validation loss: 1882.0155029296875 best Validation loss: 1882.0155029296875\n",
      "Epoch: 22400 Loss: 1726.254638671875 Validation loss: 1880.916259765625 best Validation loss: 1880.916259765625\n",
      "Epoch: 22500 Loss: 1723.343017578125 Validation loss: 1879.850341796875 best Validation loss: 1879.850341796875\n",
      "Epoch: 22600 Loss: 1720.433837890625 Validation loss: 1878.6119384765625 best Validation loss: 1878.6119384765625\n",
      "Epoch: 22700 Loss: 1717.5943603515625 Validation loss: 1877.4573974609375 best Validation loss: 1877.4573974609375\n",
      "Epoch: 22800 Loss: 1714.7943115234375 Validation loss: 1876.414306640625 best Validation loss: 1876.414306640625\n",
      "Epoch: 22900 Loss: 1712.0224609375 Validation loss: 1875.5389404296875 best Validation loss: 1875.5389404296875\n",
      "Epoch: 23000 Loss: 1709.279052734375 Validation loss: 1874.6656494140625 best Validation loss: 1874.6656494140625\n",
      "Epoch: 23100 Loss: 1706.5738525390625 Validation loss: 1873.8990478515625 best Validation loss: 1873.8990478515625\n",
      "Epoch: 23200 Loss: 1703.844970703125 Validation loss: 1873.0875244140625 best Validation loss: 1873.0875244140625\n",
      "Epoch: 23300 Loss: 1701.096435546875 Validation loss: 1872.177978515625 best Validation loss: 1872.177978515625\n",
      "Epoch: 23400 Loss: 1698.3875732421875 Validation loss: 1871.454833984375 best Validation loss: 1871.454833984375\n",
      "Epoch: 23500 Loss: 1695.656982421875 Validation loss: 1870.7071533203125 best Validation loss: 1870.7071533203125\n",
      "Epoch: 23600 Loss: 1692.9027099609375 Validation loss: 1870.08984375 best Validation loss: 1870.08984375\n",
      "Epoch: 23700 Loss: 1690.171630859375 Validation loss: 1869.481689453125 best Validation loss: 1869.481689453125\n",
      "Epoch: 23800 Loss: 1687.4501953125 Validation loss: 1868.8861083984375 best Validation loss: 1868.8861083984375\n",
      "Epoch: 23900 Loss: 1684.7635498046875 Validation loss: 1868.152587890625 best Validation loss: 1868.152587890625\n",
      "Epoch: 24000 Loss: 1682.120849609375 Validation loss: 1867.466064453125 best Validation loss: 1867.466064453125\n",
      "Epoch: 24100 Loss: 1679.48828125 Validation loss: 1866.7215576171875 best Validation loss: 1866.7215576171875\n",
      "Epoch: 24200 Loss: 1676.850341796875 Validation loss: 1865.972900390625 best Validation loss: 1865.972900390625\n",
      "Epoch: 24300 Loss: 1674.1954345703125 Validation loss: 1865.2222900390625 best Validation loss: 1865.2222900390625\n",
      "Epoch: 24400 Loss: 1671.5213623046875 Validation loss: 1864.548095703125 best Validation loss: 1864.548095703125\n",
      "Epoch: 24500 Loss: 1668.85107421875 Validation loss: 1863.961181640625 best Validation loss: 1863.9605712890625\n",
      "Epoch: 24600 Loss: 1666.1925048828125 Validation loss: 1863.521484375 best Validation loss: 1863.521484375\n",
      "Epoch: 24700 Loss: 1663.6002197265625 Validation loss: 1863.0977783203125 best Validation loss: 1863.0977783203125\n",
      "Epoch: 24800 Loss: 1661.0509033203125 Validation loss: 1862.5760498046875 best Validation loss: 1862.5760498046875\n",
      "Epoch: 24900 Loss: 1658.490966796875 Validation loss: 1861.9346923828125 best Validation loss: 1861.9346923828125\n",
      "Epoch: 25000 Loss: 1655.941162109375 Validation loss: 1861.423095703125 best Validation loss: 1861.423095703125\n",
      "Epoch: 25100 Loss: 1653.4168701171875 Validation loss: 1860.8212890625 best Validation loss: 1860.8212890625\n",
      "Epoch: 25200 Loss: 1650.8809814453125 Validation loss: 1860.171142578125 best Validation loss: 1860.171142578125\n",
      "Epoch: 25300 Loss: 1648.4029541015625 Validation loss: 1859.630859375 best Validation loss: 1859.630126953125\n",
      "Epoch: 25400 Loss: 1645.9454345703125 Validation loss: 1859.1732177734375 best Validation loss: 1859.1732177734375\n",
      "Epoch: 25500 Loss: 1643.48779296875 Validation loss: 1858.6221923828125 best Validation loss: 1858.6221923828125\n",
      "Epoch: 25600 Loss: 1641.0037841796875 Validation loss: 1857.92333984375 best Validation loss: 1857.92333984375\n",
      "Epoch: 25700 Loss: 1638.544921875 Validation loss: 1857.3719482421875 best Validation loss: 1857.3719482421875\n",
      "Epoch: 25800 Loss: 1636.11865234375 Validation loss: 1856.844970703125 best Validation loss: 1856.844970703125\n",
      "Epoch: 25900 Loss: 1633.7115478515625 Validation loss: 1856.3223876953125 best Validation loss: 1856.3223876953125\n",
      "Epoch: 26000 Loss: 1631.264892578125 Validation loss: 1855.8466796875 best Validation loss: 1855.8466796875\n",
      "Epoch: 26100 Loss: 1628.8482666015625 Validation loss: 1855.38818359375 best Validation loss: 1855.38818359375\n",
      "Epoch: 26200 Loss: 1626.4344482421875 Validation loss: 1854.9246826171875 best Validation loss: 1854.9246826171875\n",
      "Epoch: 26300 Loss: 1624.0267333984375 Validation loss: 1854.3997802734375 best Validation loss: 1854.3997802734375\n",
      "Epoch: 26400 Loss: 1621.6260986328125 Validation loss: 1853.9534912109375 best Validation loss: 1853.9534912109375\n",
      "Epoch: 26500 Loss: 1619.2550048828125 Validation loss: 1853.36083984375 best Validation loss: 1853.36083984375\n",
      "Epoch: 26600 Loss: 1616.8582763671875 Validation loss: 1852.7783203125 best Validation loss: 1852.7783203125\n",
      "Epoch: 26700 Loss: 1614.4910888671875 Validation loss: 1852.13427734375 best Validation loss: 1852.13427734375\n",
      "Epoch: 26800 Loss: 1612.1502685546875 Validation loss: 1851.5191650390625 best Validation loss: 1851.5191650390625\n",
      "Epoch: 26900 Loss: 1609.830078125 Validation loss: 1850.9278564453125 best Validation loss: 1850.9278564453125\n",
      "Epoch: 27000 Loss: 1607.451904296875 Validation loss: 1850.223876953125 best Validation loss: 1850.223876953125\n",
      "Epoch: 27100 Loss: 1605.0291748046875 Validation loss: 1849.3258056640625 best Validation loss: 1849.3258056640625\n",
      "Epoch: 27200 Loss: 1602.6556396484375 Validation loss: 1848.5635986328125 best Validation loss: 1848.5635986328125\n",
      "Epoch: 27300 Loss: 1600.3326416015625 Validation loss: 1848.0220947265625 best Validation loss: 1848.0220947265625\n",
      "Epoch: 27400 Loss: 1597.99853515625 Validation loss: 1847.260009765625 best Validation loss: 1847.260009765625\n",
      "Epoch: 27500 Loss: 1595.6641845703125 Validation loss: 1846.5780029296875 best Validation loss: 1846.5780029296875\n",
      "Epoch: 27600 Loss: 1593.39892578125 Validation loss: 1846.193603515625 best Validation loss: 1846.193603515625\n",
      "Epoch: 27700 Loss: 1591.186279296875 Validation loss: 1845.87744140625 best Validation loss: 1845.8734130859375\n",
      "Epoch: 27800 Loss: 1588.98974609375 Validation loss: 1845.68505859375 best Validation loss: 1845.683349609375\n",
      "Epoch: 27900 Loss: 1586.81201171875 Validation loss: 1845.528564453125 best Validation loss: 1845.525146484375\n",
      "Epoch: 28000 Loss: 1584.5491943359375 Validation loss: 1845.2294921875 best Validation loss: 1845.2275390625\n",
      "Epoch: 28100 Loss: 1582.3453369140625 Validation loss: 1845.00927734375 best Validation loss: 1845.00927734375\n",
      "Epoch: 28200 Loss: 1580.19677734375 Validation loss: 1844.6912841796875 best Validation loss: 1844.688232421875\n",
      "Epoch: 28300 Loss: 1578.079345703125 Validation loss: 1844.4014892578125 best Validation loss: 1844.400146484375\n",
      "Epoch: 28400 Loss: 1575.94921875 Validation loss: 1844.154052734375 best Validation loss: 1844.154052734375\n",
      "Epoch: 28500 Loss: 1573.8115234375 Validation loss: 1843.8758544921875 best Validation loss: 1843.8758544921875\n",
      "Epoch: 28600 Loss: 1571.7105712890625 Validation loss: 1843.7529296875 best Validation loss: 1843.74169921875\n",
      "Epoch: 28700 Loss: 1569.68359375 Validation loss: 1843.743408203125 best Validation loss: 1843.7099609375\n",
      "Epoch: 28800 Loss: 1567.6875 Validation loss: 1843.78515625 best Validation loss: 1843.7099609375\n",
      "Epoch: 28900 Loss: 1565.704833984375 Validation loss: 1843.7806396484375 best Validation loss: 1843.7099609375\n",
      "Epoch: 29000 Loss: 1563.7386474609375 Validation loss: 1843.7325439453125 best Validation loss: 1843.7099609375\n",
      "Epoch: 29100 Loss: 1561.802001953125 Validation loss: 1843.632080078125 best Validation loss: 1843.6239013671875\n",
      "Epoch: 29200 Loss: 1559.89404296875 Validation loss: 1843.5531005859375 best Validation loss: 1843.543701171875\n",
      "Epoch: 29300 Loss: 1558.009765625 Validation loss: 1843.5145263671875 best Validation loss: 1843.509521484375\n",
      "Epoch: 29400 Loss: 1556.12646484375 Validation loss: 1843.4825439453125 best Validation loss: 1843.4720458984375\n",
      "Epoch: 29500 Loss: 1554.2554931640625 Validation loss: 1843.5413818359375 best Validation loss: 1843.4720458984375\n",
      "Epoch: 29600 Loss: 1552.3770751953125 Validation loss: 1843.5714111328125 best Validation loss: 1843.4720458984375\n",
      "Epoch: 29700 Loss: 1550.50048828125 Validation loss: 1843.6689453125 best Validation loss: 1843.4720458984375\n",
      "Epoch: 29800 Loss: 1548.6424560546875 Validation loss: 1843.9300537109375 best Validation loss: 1843.4720458984375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_val_loss = float('inf')\n",
    "training_loss = np.array([])\n",
    "validation_loss = np.array([])\n",
    "last_val_loss = float('inf')\n",
    "count = 0\n",
    "\n",
    "for n in range(NUMBER_OF_EPOCH):\n",
    "    model.train()\n",
    "    y_pred = model(X_train)[:, 0]\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    training_loss = np.append(training_loss, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_pred = model(X_val)[:, 0]\n",
    "    val_loss = loss_fn(y_pred, y_val)\n",
    "    validation_loss = np.append(validation_loss, val_loss.item())\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model, 'mlp_model.pth')\n",
    "    \n",
    "    if n % 100 == 0:\n",
    "        print(f'Epoch: {n} Loss: {loss.item()}'f' Validation loss: {val_loss.item()}'f' best Validation loss: {best_val_loss}')\n",
    "        \n",
    "    if last_val_loss < val_loss:\n",
    "        count += 1\n",
    "        if count == 25:\n",
    "            break\n",
    "    else:\n",
    "        count = 0\n",
    "    last_val_loss = val_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x31465ba50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(training_loss, label='Training Loss')\n",
    "plt.plot(validation_loss, label='Validation Loss')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/64/cy9kvd894_bfkfb71dsbxt2w0000gn/T/ipykernel_10139/228361571.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('mlp_model.pth')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "df = pd.read_csv('data/test.csv')\n",
    "model = torch.load('mlp_model.pth')\n",
    "model.eval()\n",
    "\n",
    "index = df['id']\n",
    "df = df.drop(['id'], axis=1)\n",
    "X = pre.encoder(df)\n",
    "X = pre.standardize(X, scaler=pickle.load(open('scaler.pkl', 'rb')))\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_pred = model(X)[:, 0]\n",
    "\n",
    "df = pd.DataFrame(y_pred.detach().numpy(), columns=['price'])\n",
    "df = pd.concat([index, df], axis=1)\n",
    "df.rename(columns={'price': 'answer'}, inplace=True)\n",
    "df.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
